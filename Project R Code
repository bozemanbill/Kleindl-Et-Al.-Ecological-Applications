###################################################
#  Ecological Applications 
#  Integrating Variance into Ecological Assessment: A Practical Application of Modern Portfolio Theory                              
#  Author Names: Kleindl, W.J., P.C. Stoy, F. Kerins, M.C. Rains                             
#  Contact; william.kleindl@montana.edu              
###################################################
# Section 1 Library AND WD Prep ----------------------------------------------

###########Libraries and working directory. ##############
###### Warning some libraries may be deprecated #########
##### Also, my R skills are a lot like my carpentry skills. I can make a chair, 
#####  and you can sit in it, but it will not be beautiful!  ######

library(MuMIn)
library(reshape)
library(rgdal)
library(robustbase)
library(boot)
library(caret)
library(data.table)
library(devtools)
library(dismo)
library(doParallel)
library(dplyr)
library(e1071)
library(gdalUtils)
library(ggplot2)
library(ggrepel)
library(gtools)
library(landsat)
library(maptools)
library(MuMIn)
library(plyr)
library(PortfolioAnalytics)
library(pracma)
library(randomForest)
library(rasta)
library(raster)
library(RColorBrewer)
library(reshape)
library(reshape)
library(reshape2)
library(rgdal)
library(rgeos)
library(rlist)
library(robustbase)
library(RStoolbox)
library(scales)
library(SDMTools)
library(sf)
library(shapefiles)
library(snow)
library(sp)
library(stats)
library(terra) 
library(tibble)
library(vegan)


wd<-setwd("YOUR PATH")


# Section 2 GEE Code -------------------------------------------------------

####Start by collecting Landsat imagery from Google Earth Engine. ##############

### The following code is FOR GOOGLE EARTH ENGINE AND IS IN JAVA!!!!!
### This will will help acquire LS data from 1984 to 2020 with cloud mask
### Composites of multiple paths are done here in GEE

# Landsat 5 – 1984-2011
# Landsat 7 – 2012
# Landsat 8 – 2013-2018
# See this http://www.acgeospatial.co.uk/time-series-on-landsat-data-gee/ 
#   From GEE Code
# // This example demonstrates the use of the Landsat 4, 5, 7 Collection 2,
# // Level 2 QA_PIXEL band (CFMask) to mask unwanted pixels.
# 
# function maskL457sr(image) {
#   // Bit 0 - Fill
#   // Bit 1 - Dilated Cloud
#   // Bit 2 - Unused
#   // Bit 3 - Cloud
#   // Bit 4 - Cloud Shadow
#   var qaMask = image.select('QA_PIXEL').bitwiseAnd(parseInt('11111', 2)).eq(0);
#   var saturationMask = image.select('QA_RADSAT').eq(0);
#   
#   // Apply the scaling factors to the appropriate bands.
#   var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);
#   var thermalBand = image.select('ST_B6').multiply(0.00341802).add(149.0);
#   
#   // Replace the original bands with the scaled ones and apply the masks.
#   return image.addBands(opticalBands, null, true)
#   .addBands(thermalBand, null, true)
#   .updateMask(qaMask)
#   .updateMask(saturationMask);
# }
# 
# // // Map the function for LS 7 .
# // var collection = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2')
# //.filter(ee.Filter.or(
#   //    ee.Filter.and(ee.Filter.eq('WRS_PATH', 42),         
#                       //                 ee.Filter.eq('WRS_ROW', 26)),
#   //    ee.Filter.and(ee.Filter.eq('WRS_PATH', 41), 
#                       //                  ee.Filter.eq('WRS_ROW', 26)),
#   //    ee.Filter.and(ee.Filter.eq('WRS_PATH', 41), 
#                       //                  ee.Filter.eq('WRS_ROW', 27))))
# //        .filterDate('2008-06-01', '2008-09-15')
# //                     .map(maskL457sr);
# 
# // Map the function for LS 5 .
# var collection = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2')
# .filter(ee.Filter.or(
#   ee.Filter.and(ee.Filter.eq('WRS_PATH', 42),         
#                 ee.Filter.eq('WRS_ROW', 26)),
#   ee.Filter.and(ee.Filter.eq('WRS_PATH', 41), 
#                 ee.Filter.eq('WRS_ROW', 26)),
#   ee.Filter.and(ee.Filter.eq('WRS_PATH', 41), 
#                 ee.Filter.eq('WRS_ROW', 27))))
# .filterDate('2008-06-01', '2008-09-15')
# .map(maskL457sr);
# var composite = collection.median()
# .select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7', 'ST_B6']);
# 
# print(composite)
# 
# var proj = ee.Projection('EPSG:32612');
# var flatmedr = composite.reproject(proj, null, 30)
# 
# // Display the results.
# Map.setCenter(-114.1577, 48.7104,8)
# Map.addLayer(composite, {bands: ['SR_B3', 'SR_B2', 'SR_B1'], min: 0, max: 0.3});
# 
# Export.image.toDrive({
#   image: compositer,
#   description: 'flhd_19_mos',
#   scale: 30,
#   folder: 'RS_image',
#   region: roi
# });
# 
# // make sure ROI river is loaded
# // repeat for each year 
# // note BANDS ARE DIFFERENT between 5 and 8
# 
# https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LT05_C02_T1_L2 
# LS 8 https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C02_T1_L2#bands
# 
# 
# // This example demonstrates the use of the Landsat 8 Collection 2, Level 2
# // QA_PIXEL band (CFMask) to mask unwanted pixels.
# 
# function maskL8sr(image) {
#   // Bit 0 - Fill
#   // Bit 1 - Dilated Cloud
#   // Bit 2 - Cirrus
#   // Bit 3 - Cloud
#   // Bit 4 - Cloud Shadow
#   var qaMask = image.select('QA_PIXEL').bitwiseAnd(parseInt('11111', 2)).eq(0);
#   var saturationMask = image.select('QA_RADSAT').eq(0);
#   
#   // Apply the scaling factors to the appropriate bands.
#   var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);
#   var thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0);
#   
#   // Replace the original bands with the scaled ones and apply the masks.
#   return image.addBands(opticalBands, null, true)
#   .addBands(thermalBands, null, true)
#   .updateMask(qaMask)
#   .updateMask(saturationMask);
# }
# 
# var flat = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')
# .filter(ee.Filter.or(
#   ee.Filter.and(ee.Filter.eq('WRS_PATH', 42),         
#                 ee.Filter.eq('WRS_ROW', 26)),
#   ee.Filter.and(ee.Filter.eq('WRS_PATH', 41), 
#                 ee.Filter.eq('WRS_ROW', 26)),
#   ee.Filter.and(ee.Filter.eq('WRS_PATH', 41), 
#                 ee.Filter.eq('WRS_ROW', 27))))
# .filterDate('2008-06-01', '20108-09-15')
# .map(maskL8sr);
# 
# Map.setCenter(-114.1577, 48.7104,8)
# 
# var flatmed = flat.median()
# .select(['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'ST_B10']);
# 
# var proj = ee.Projection('EPSG:32612');
# var flatmedr = flatmed.reproject(proj, null, 30)
# 
# // print('Projection, crs, and crs_transform:', flatmedr.projection());
# // print('Scale in meters:', flatmedr.projection().nominalScale());
# 
# Map.addLayer(flatmed, {bands: ['SR_B4', 'SR_B3', 'SR_B2'], min: 0, max: 0.3}, "flatmed");
# //Map.addLayer(flatmedr, {bands: ['SR_B4', 'SR_B3', 'SR_B2'], min: 0, max: 0.3}, "flatmedr");
# 
# Export.image.toDrive({
#   image: flatmedr,
#   description: 'flhd_13_mos',
#   scale: 30,
#   folder: 'RS_image',
#   region: roi
# });


# Section 3 Training and Classification ------------------------------------------------

##########################get those sample poly#################################################
myproj<-"+proj=utm +zone=12 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0" 

#below if for poly file One shape file with multiple classes. field that identifies the classes "Classname").  
#The shape file can be of any feature type, but different code must be used for points versus any other type.
#flor LS 8

Yr<-05
file<-sprintf('RS Image/LS8/path 42/flhd_%d_42.tif', yr)
img<-brick(file)
names(img) <- c('blue','grn','red','NIR','SWIR1','SWIR2','THRM')
img <- subset(img, c("blue", "grn", "red", "NIR", "SWIR1", "SWIR2"))

valid.locations <- shapefile("Classifiction Points/13_train_polys_dis.shp")
valid.full <- NULL  
for (i in 1:length(unique(valid.locations[["Classname"]]))){
  valid.type <- unique(valid.locations[["Classname"]])[i]
  valid.type.locations <- valid.locations [valid.locations[["Classname"]] == valid.type,]
  valid.by.class <- extract(img, valid.type.locations)
  ### If the data is in a point shapefile instead of polygons, skip this next line.
  valid.by.class <- as.data.frame(do.call("rbind", valid.by.class))
  valid.by.class <- cbind(valid.by.class, "Classname" = valid.type)
  valid.full <- rbind(valid.full, valid.by.class)
}

#Check for NA's and remove them
row.has.na <- apply(valid.full, 1, function(x){any(is.na(x))})
sum(row.has.na)
final.filtered <- valid.full[!row.has.na,]
train.full <- final.filtered

########Randomly select accuracy data from training ##############

### 4.2.5 Random extraction of accuracy assessment data from imported training data. This is a common practice.  
#The statistical appropriateness of this approach is not addressed in this article, although analysts 
#should be aware of issues related to use of non-independent data for validating results.
### Get the number of entries (rows) in the data.
x <- nrow (train.full) 
### Create index numbers for extracting the training data.  The example is set for 75% training, but this can be changed.
train.index <- sample (1:x, (x * 0.75)) 
### Create index numbers for the rest for validation.
valid.index <- setdiff (1:x, train.index) 
### Extract the training data to a temporary object.
train.temp <- train.full[train.index,] 
### Extract the validation data.
valid.full <- train.full[valid.index,] 
### Rename the training data to match the rest of the code.
train.full <- train.temp

####Set up Agnostic Classification Analysis##################
# categorical variables represented by numbers must be preceded by "factor" (e.g., if
#the classes are designated 1, 2, 3 . . ., the equation response variable should be "factor('Classname')") 
#above changed for poly data
equation <- factor(Classname) ~ .
equation <- as.formula(equation)

### Already selected the method that is the fastest and the best - Random Forest.

# Start the clock!
ptm <- proc.time()

train.model.rf <- train(equation, method = "rf", data = train.full)
predict.model.rf <- predict (train.model.rf, newdata = valid.full)
results <- confusionMatrix(predict.model.rf, valid.full$Classname)
capture.output(x, results, file = "results_poly_rf.txt", append = TRUE)

# Stop the clock
proc.time() - ptm

### IMPORTANT!!!  The above code is for LS8 and should be like below!!!
# Start the clock!

##for ls5 fun above code with 2005 reference data
#train.model_ls5.rf <- train(equation, method = "rf", data = train.full)
#predict.model_ls.rf <- predict (train.model.rf, newdata = valid.full)
#results_ls <- confusionMatrix(predict.model.rf, valid.full$Classname)
#capture.output(x, results_ls, file = "results_poly_rf_ls5.txt", append = TRUE)

##for ls8 fun above code with 2013 reference data
#train.model_ls8.rf <- train(equation, method = "rf", data = train.full)
#predict.model_ls8.rf <- predict (train.model.rf, newdata = valid.full)
#results_ls8 <- confusionMatrix(predict.model.rf, valid.full$Classname)
#capture.output(x, results_ls8, file = "results_poly_rf_ls8.txt", append = TRUE)

#########Classify all years using RF#####################################################

registerDoParallel(cores=3) ### Replace x with number of cores you wish to allocate.

## Load Rasters each band is separate and in different folders
#so need to loop through folders, stack rasters into a brick, name brick by year
#apply class model then make map
#load stack
#run loop for following years. 
files2<-list.files(wd, recursive=F)
e <- extent(231180, 278000, 5330000, 5480000)

yr=2008

for(yr in 1985:2011){
  file<-sprintf('F:/Flathead RS/Level 1 Tier 1 SR/Practice/Path 42/flhd_41_%d.tif', yr)
  img<-brick(file)
  names(img) <- c('blue','grn','red','NIR','SWIR1','THRM','SWIR2')
  img <- subset(img, c("blue", "grn", "red", "NIR", "SWIR1", "SWIR2"))
  beginCluster(4)
  clusterR(img,raster::predict, args=list(model=train.model.rf),
           filename=sprintf("F:/Flathead RS/Level 1 Tier 1 SR/Maps/class_41_%d.tif", yr), format="HFA", datatype="FLT4S",
           overwrite=TRUE, na.action=na.omit)
  endCluster()
  yr<-yr+1
} 

#### LS8 #################
yr=13

for(yr in 13:18){
  file<-sprintf('RS Image/LS8/path 42/flhd_%d_42.tif', yr)
  img<-brick(file)
  names(img) <- c('blue','grn','red','NIR','SWIR1','SWIR2','THRM')
  img <- subset(img, c("blue", "grn", "red", "NIR", "SWIR1", "SWIR2"))
  beginCluster(4)
  clusterR(img,raster::predict, args=list(model=train.model.rf),
           filename=sprintf("RS Image/LS8/path 42/class_42_%d.tif", yr), format="HFA", datatype="FLT4S",
           overwrite=TRUE, na.action=na.omit)
  endCluster()
  yr<-yr+1
}

####REPEAT FOR PATH 41#####################
####Merged data from GEE###
yr=19
for(yr in 19:20){
  file<-('RS Image/LS8/flhd_19.tif')
  img<-brick(file)
  names(img) <- c('blue','grn','red','NIR','SWIR1','SWIR2','THRM')
  img <- subset(img, c("blue", "grn", "red", "NIR", "SWIR1", "SWIR2"))
  img <-projectRaster(img, crs=proj, res=c(30,30), method="ngb")
  beginCluster(4)
  clusterR(img,raster::predict, args=list(model=train.model.rf),
           filename=("RS Image/LS8/path 42/class_19"), format="HFA", datatype="FLT4S",
           overwrite=TRUE, na.action=na.omit)
  endCluster()
  yr<-yr+1
}

XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
#Once 41 and 42 are classified, clip and merge them unless merged in GEE which is better…
clippy <- raster("F:/Flathead RS/Level 1 Tier 1 SR/Practice/2005_mask.img")
e <- extent(231180, 275850, 5330010, 5478630)
myproj<-"+proj=utm +zone=12 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0" 
proj<-crs(clippy)

### LS8###
yr=13
for(yr in 13:18){
  file<-sprintf("RS Image/LS8/path 42/class_42_%d.img", yr)
  img_42<-raster(file)
  img <-projectRaster(img_42, crs=proj)
  img_42 <- crop(img, e)
  file<-sprintf("RS Image/LS8/path 41/class_41_%d.img", yr)
  img_41<-raster(file)
  img_41 <- crop(img_41, e)
  img_42 <-resample(img_42, img_41, method="bilinear")
  mos <- mosaic(img_42,img_41, fun=min)
  img2 <-resample(mos, clippy, method="bilinear")
  bob<-mask(img2, clippy)
  writeRaster(bob, filename=sprintf("RS Image/LS8/Study Data/%d_class.img", yr), overwrite=TRUE)
  yr<-yr+1
}

##### But for the GEE Composited data. Do this####
fldpln <- readOGR("Current Data/Clipped study area/tot_4pix12.shp")
fldpln <- spTransform(fldpln, crs(proj))
clippy <- raster("H:/Flathead RS/Level 1 Tier 1 SR/Practice/2005_mask.img")
#fldpln <- rasterize(fldpln, clippy)
fltmask <- rasterToPolygons(clippy)

file<-("D:/Dropbox/University Work/Dynamics and Ecology/RS Image/LS8/path 42/class_19.img")
img_42<-raster(file)
img_42 <- crop(img_42, fltmask)
img2 <-resample(img_42, clippy, method="ngb")
bob<-mask(img2, clippy)
as.data.frame(freq(img2))
writeRaster(bob, filename= ("RS Image/LS8/Study Data/2019_class.img"), overwrite=TRUE)
yr<-yr+1


# Section 4 apply classification to all years, clean with rules, and verify  ------------------

##Once the classification method was set, I applied that to all years. 
##Then I cleaned up the maps by clipping them to areas of interest and classifying 
## them by known class covers (river, road, etc.) and smooth salt and pepper. Below…

##############load Rasters and polylines#############
#landsat
img <- raster("Practice/2005_mask.img")
## River Ortho (containing zones of interest)
ortho <- raster("Practice/ortho2_mask.img")
## Glac boundry (containing zones of interest)
glac <- raster("Practice/glac_mask.img")
## Road Data using only paved and gravel assuming no change from 1985
road <- raster("Practice/road_mask.img")
## Rail road Data assuming no change from 1985
rail <- raster("D:/Dropbox/University Work/Dynamics and Ecology/GIS Background/Roads/rail_mask.img")

##########Reclass by attribute############################
# GLAC change pasture to meadow: 
rr <- mask(img, match(glac, 1))
rr[rr == 10] <- 6
# add classification to the original file - "join" the original, and reclassified raster file 
img[match(glac, 1)] <- rr@data@values[!is.na(rr@data@values)]

# ORTHO change urban to cobble within river and parafluve: ROADS to change all intersected cells to urban: 
#Cobble to urban first
rr <- mask(img, match(ortho, 0))
#urban to cobble
rr[rr == 7] <- 11
##Now within active river
rr <- mask(img, match(ortho, 1))
#urban to cobble
rr[rr == 11] <- 7
#ag, post fire, and clear cut to meadow 
rr[rr == 10] <- 6
rr[rr == 13] <- 6
rr[rr == 15] <- 6
# add classification to the original file - "join" the original, and reclassified raster file 
img[match(ortho, 1)] <- rr@data@values[!is.na(rr@data@values)]

#Post fix with final maps to remove clear cut in GLAC
# to fix this clear cut in GLAC issue
## Glac boundry (containing zones of interest) NEW MASK FOR FINAL MAPS
glac <- raster("Current Data/Clipped study area/glac3.img")
for(yr in 1984:2018){
  file<-sprintf("RS Image/Final_Maps/draft/%d_class_final.img", yr)
  img <- raster(file)
  rr <- mask(img, match(glac, 1))
  #clear cut to field based on confusion matrix 
  rr[rr == 15] <- 6
  bub <- merge(rr, img)
  writeRaster(bub, filename=sprintf("RS Image/Final_Maps/%d_class_final.img", yr), overwrite=TRUE)
  yr<-yr+1
}
#############moving 3X3 window to Focal Window Smoothing#################
#clean up noise to apply majority filter
r <- img 
img_modal<-focal(r, w=matrix(1,3,3), fun=modal)
#img_mean<-focal(r, w=matrix(1,3,3), fun=mean)
#img <- img_modal

#############Reclass roads######################################
# ROADS to change all intersected cells to urban: 
# add classification to the original file - "join" the original, and reclassified raster file 
img[match(road, 1)] <- 11
img[match(rail, 1)] <- 11

#####################Clean Up all years###############################################
for(yr in 2019:2020){
  file<-sprintf("RS Image/LS8/Study Data/%d_class.img", yr)
  img <- raster(file)
  rr <- mask(img, match(glac, 1))
  rr[rr == 10] <- 6
  rr[rr == 15] <- 6
  img[match(glac, 1)] <- rr@data@values[!is.na(rr@data@values)]
  rr <- mask(img, match(ortho, 0))
  rr[rr == 7] <- 11
  rr <- mask(img, match(ortho, 1))
  rr[rr == 11] <- 7
  rr[rr == 10] <- 6
  rr[rr == 13] <- 6
  rr[rr == 15] <- 6
  img[match(ortho, 1)] <- rr@data@values[!is.na(rr@data@values)]
  img<-focal(img, w=matrix(1,3,3), fun=modal)
  img[match(road, 1)] <- 11
  img[match(rail, 1)] <- 11
  writeRaster(img, filename=sprintf("RS Image/Final_Maps/%d_clean.img", yr), overwrite=TRUE)
  yr<-yr+1
} 
##############lOOK AT IT######################################
opar <- par(mfrow=c(1, 2)) # allow 2 plots side-by-side
e <- extent(c(272000, 278000, 5365000, 5372500))
plot(img, ext=e,  legend=FALSE)
plot(img_modal, ext=e,  legend=FALSE)
plot(img_mean, ext=e,  legend=FALSE)
#to reset the plot stuff
par(opar)

########## clean classified images with condition rules ########

###Then, set up a rule for the final clean-up of the maps. 
##For example, if it is a mature forest in one year, it can’t be a river in the previous year. 
##But if it is cobble, it can be river the previous year. Based on the 2005 as the base condition. 

#### Conditional Statements ############
######## Forward in Time #################
forward = function(old,new){
  (ifelse(new==1 & old==2, old,
          ifelse(new==1 & old==4, old,
                 ifelse(new==1 & old==5, old,
                        ifelse(new==1 & old==6, old, 
                               ifelse(new==1 & old==7, old, 
                                      ifelse(new==1 & old==8, old, 
                                             ifelse(new==1 & old==10, old, 
                                                    ifelse(new==1 & old==11, old,
                                                           ifelse(new==1 & old==13, old,
                                                                  ifelse(new==1 & old==15, old,
                                                                         ifelse(new==2 & old==1, old,
                                                                                ifelse(new==2 & old==5, old,
                                                                                       ifelse(new==2 & old==6, old, 
                                                                                              ifelse(new==2 & old==7, old, 
                                                                                                     ifelse(new==2 & old==8, old, 
                                                                                                            ifelse(new==2 & old==10, old, 
                                                                                                                   ifelse(new==2 & old==11, old,
                                                                                                                          ifelse(new==2 & old==13, old,
                                                                                                                                 ifelse(new==2 & old==15, old, 
                                                                                                                                        ifelse(new==4 & old==1, old,
                                                                                                                                               ifelse(new==4 & old==2, old,
                                                                                                                                                      ifelse(new==4 & old==11, old,
                                                                                                                                                             ifelse(new==5 & old==11, old,
                                                                                                                                                                    ifelse(new==6 & old==11, old,
                                                                                                                                                                           ifelse(new==7 & old==11, old,
                                                                                                                                                                                  ifelse(new==8 & old==11, old,
                                                                                                                                                                                         ifelse(new==10 & old==11, old,
                                                                                                                                                                                                ifelse(new==13 & old==6, old,
                                                                                                                                                                                                       ifelse(new==13 & old==11, old,
                                                                                                                                                                                                              ifelse(new==15 & old==6, old, 
                                                                                                                                                                                                                     ifelse(new==15 & old==11, old, new ))))))))))))))))))))))))))))))))
}

yr <- 2005
old <- raster("RS Image/Final_Maps/2005_class_final.img")
for(yr in 2019:2020){
  yr <- yr + 1
  new <- sprintf("RS Image/Final_Maps/%d_clean.img", yr)
  new <- raster(new)
  old <- overlay(old,new, fun=forward)
  writeRaster(old, filename=sprintf("RS Image/Final_Maps/draft2/%d_class_final.img", yr), overwrite=TRUE)
}

##############  Back in time ############
new_back = function(r1,r2){
  (ifelse(r2==1 & r1==2, r1,
          ifelse(r2==2 & r1==1, r1,
                 ifelse(r2==4 & r1==6, r1,
                        ifelse(r2==4 & r1==1, r1, 
                               ifelse(r2==4 & r1==15, r1, 
                                      ifelse(r2==6 & r1==4, r1, 
                                             ifelse(r2==7 & r1==4, r1, 
                                                    ifelse(r2==6 & r1==2, r1,
                                                           ifelse(r2==13 & r1==6, r1,
                                                                  ifelse(r2==7 & r1==2, r1,
                                                                         ifelse(r2==8 & r1==10, r1, 
                                                                                ifelse(r2==10 & r1==8, r1,
                                                                                       ifelse(r2==15 & r1==10, r1,
                                                                                              ifelse(r2==11 & r1==7, r1,
                                                                                                     ifelse(r2==11 & r1==10, r1,
                                                                                                            ifelse(r2==11 & r1==15, r1,
                                                                                                                   ifelse(r2==13 & r1==10, r1,
                                                                                                                          ifelse(r2==13 & r1==15, r1,
                                                                                                                                 ifelse(r2==15 & r1==13, r1,
                                                                                                                                        ifelse(r2==15 & r1==1, r1,
                                                                                                                                               ifelse(r2==15 & r1==4, r1,
                                                                                                                                                      ifelse(r2==15 & r1==6, r1,
                                                                                                                                                             ifelse(r2==15 & r1==2, r1, 
                                                                                                                                                                    ifelse(r2==15 & r1==13, r1, r2)))))))))))))))))))))))))}
yr <- 2004
r.class <- raster("RS Image/LS8/Post_proc/2005_clean.img")
while (yr > 1983){
  older <- sprintf("RS Image/LS8/Post_proc/%d_clean.img", yr)
  newer <- r.class
  older <- raster(older)
  r.class <- overlay(newer,older, fun=new_back)
  writeRaster(r.class, filename=sprintf("RS Image/Final_Maps/Final_final_maps/%d_class_final.img", yr), overwrite=TRUE)
  yr <- yr-1
}

#lastly move 2005 over## 
r1 <- raster("RS Image/LS8/Post_proc/2005_clean.img")
writeRaster(r1, filename=("RS Image/Final_Maps/2005_class_final.img"), overwrite=TRUE)

########################### Check accuracy ###########################################
#below if for poly file One shapefile with multiple classes. field that identifies the classes "Classname").  
#The shapefile can be of any feature type, but different code must be used for points versus any other type.  
valid_05 <- shapefile("D:/Dropbox/University Work/Dynamics and Ecology/Classifiction Points/05_train_polys_dis.shp")
valid_91 <- shapefile("D:/Dropbox/University Work/Dynamics and Ecology/Classifiction Points/91_train_polys_dis.shp")
valid_09 <- shapefile("D:/Dropbox/University Work/Dynamics and Ecology/Classifiction Points/09_train_polys_dis.shp")
valid_13 <- shapefile("D:/Dropbox/University Work/Dynamics and Ecology/Classifiction Points/13_train_polys_dis.shp")
valid_16 <- shapefile("D:/Dropbox/University Work/Dynamics and Ecology/Classifiction Points/16_train_polys_dis.shp")

####Final map
r1_05 <- raster("RS Image/Final_Maps/draft/2005_class_final.img")
r1_91 <- raster("RS Image/Final_Maps/draft/1991_class_final.img")
r1_09 <- raster("RS Image/Final_Maps/draft/2009_class_final.img")
r1_13 <- raster("RS Image/Final_Maps/draft/2013_class_final.img")
r1_16 <- raster("RS Image/Final_Maps/draft/2016_class_final.img")

#### For Each Year ####
#myproj<-"+proj=utm +zone=12 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0" 

#below if for poly file One shapefile with multiple classes. field that identifies the classes "class").  
#The shapefile can be of any feature type, but different code must be used for points versus any other type.  
valid.locations <- (valid_16)
valid.full <- NULL  
for (i in 1:length(unique(valid.locations[["Classname"]]))){
  valid.type <- unique(valid.locations[["Classname"]])[i]
  valid.type.locations <- valid.locations [valid.locations[["Classname"]] == valid.type,]
  #not working ask rick?
  valid.by.class <- raster::extract(r1_16, valid.type.locations)
  ### If the data is in a point shapefile instead of polygons, skip this next line.
  valid.by.class <- as.data.frame(do.call("cbind", valid.by.class))
  valid.by.class <- cbind(valid.by.class, "Classname" = valid.type)
  valid.full <- rbind(valid.full, valid.by.class)
}
names(valid.full) <- c("Prediction", "Validation")

pred <- as.data.frame(factor(valid.full$Prediction))
val <- as.data.frame(factor(valid.full$Validation))
names(pred) <- "Prediction"
names(val) <- "Validation"
pred <- as.data.frame(pred)
val <- as.data.frame(val)
results_16 <- confusionMatrix(pred$Prediction, val$Validation)

print(results_91)
print(results_05)
print(results_09)
print(results_13)
print(results_16)


# Section 5 RS Analysis ---------------------------------------------------

### In this section, I apply metric scores for each pixel. These metrics are:
### Fragmentation, Patch Diversity, Land Use. They are applied to the floodplain
### and buffer by reach. Those reaches were defined in ESRI GIS by the methods described
### in the paper. The scores were also applied at different scales. 

############## frequency of cover for whole river over time ############
r1_84 <- raster("RS Image/Final_Maps/1984_class_final.img")
class <- as.data.frame(freq(r1_84))

for(yr in 1985:2020){
  file <- sprintf("RS Image/The Final Maps/%d_class_final.img", yr)
  r <- raster(file)
  r_freq <- as.data.frame(freq(r))
  class <- cbind(class,r_freq[,2])
  yr <- yr+1
}

x <- c("class", c(1984:2018))

names(class) <- x
head(class[-12,])
tail(class[-12,])

write.csv(class[-12,], file = "Current Data/1Total River_Attributes/class_across_years.csv")

############## frequency of cover by site and by buffer over time ############
#prepping site DF
buf <- readOGR("Current Data/Clipped study area/Buffer_clipped2.shp")
fldpln <- readOGR("Current Data/Clipped study area/fldpln_clipped2.shp")
merg_pln <- readOGR("Current Data/Clipped study area/merged_clipped.shp")
tot_pln <- readOGR("Current Data/Clipped study area/fp_tot_LU.shp")
tot_buf <- readOGR("Current Data/Clipped study area/buf_tot_LU.shp")
projras <- "+proj=utm +zone=12 +datum=WGS84 +units=m +no_defs" 
#projras <- "+proj=utm +zone=12 +ellps=WGS84 +towgs84=0,0,0,-0,-0,-0,0 +units=m +no_def" 
buf <- spTransform(buf, crs(projras))
fldpln <- spTransform(fldpln, crs(projras))
merg_pln <- spTransform(merg_pln, crs(projras))
tot_pln <- spTransform(tot_pln, crs(projras))
tot_buf <- spTransform(tot_buf, crs(projras))


## Set up df
dfbuf <- as.data.frame(buf)
df_fp <- as.data.frame(fldpln)
df_mrg <- as.data.frame(merg_pln)

###Loop through years With buffer data
yr <- 1984
for(yr in 1984:2020){
  file <- sprintf("RS Image/The Final Maps/%d_class_final.img", yr)
  r <- raster(file)  
  v <- raster::extract(r, buf)
  v.counts <- (lapply(v,table))
  v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
  v.df <- lapply(v.pct, data.frame)
  x <- NULL
  for(i in 1:length(v.df)){
    # row-bind the running df with the table made into a df, and 
    #also prepend column "reach" with current iteration
    x <- rbind(x, data.frame(i, v.df[[i]]))
  }
  colnames(x) <- c("samp", "class", "pct")
  x <- reshape(x, idvar = "samp", timevar = "class", direction = "wide")
  x[is.na(x)] <- 0 
  rownames(x) <- c(43:1)
  write.csv(x, file = sprintf("Current Data/buf_pct/2021_new/%d_buf_pct.csv", yr))
  print (yr)
  yr <- yr+1
}

###Loop through years With riparian data
yr <- 1984
for(yr in 1984:2020){
  file <- sprintf("RS Image/The Final Maps/%d_class_final.img", yr)
  r <- raster(file)  
  v <- raster::extract(r, fldpln)
  v.counts <- (lapply(v,table))
  v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
  v.df <- lapply(v.pct, data.frame)
  x <- NULL
  for(i in 1:length(v.df)){
    # row-bind the running df with the table made into a df, and 
    #also prepend column "reach" with current iteration
    x <- rbind(x, data.frame(i, v.df[[i]]))
  }
  colnames(x) <- c("samp", "class", "pct")
  x <- reshape(x, idvar = "samp", timevar = "class", direction = "wide")
  x[is.na(x)] <- 0 
  rownames(x) <- c(43:1)
  write.csv(x, file = sprintf("Current Data/fldpln_pct/2021_new/%d_fldpln_pct.csv", yr))
  print (yr)
  yr <- yr+1
}

###Loop through years With total data
# for(yr in 1984:2005){
#   file <- sprintf("RS Image/Final_Maps/%d_class_final.img", yr)
#   r <- raster(file)
#   v <- raster::extract(r, tot_buf)
#   v.counts <- (lapply(v,table))
#   v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
#   v.df <- lapply(v.counts , data.frame)
#   x <- NULL
#   for(i in 1:length(v.df)){
#     # row-bind the running df with the table made into a df, and
#     #also prepend column "reach" with current iteration
#     x <- rbind(x, data.frame(i, v.df[[i]]))
#   }
#   colnames(x) <- c("reach", "class", "pix")
#   x <- reshape(x, idvar = "reach", timevar = "class", direction = "wide")
#   x[is.na(x)] <- 0
#   write.csv(x, file = sprintf("Current Data/1Total River_Attributes/tot_cnt_class/%d_totbuf_cnt.csv", yr))
#   print (yr)
#   yr <- yr+1
# }

###Loop through years With merged data

for(yr in 1984:2020){
  file <- sprintf("RS Image/The Final Maps/%d_class_final.img", yr)
  r <- raster(file)  
  v <- raster::extract(r, merg_pln)
  v.counts <- (lapply(v,table))
  v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
  v.df <- lapply(v.pct, data.frame)
  x <- NULL
  for(i in 1:length(v.df)){
    # row-bind the running df with the table made into a df, and 
    #also prepend column "reach" with current iteration
    x <- rbind(x, data.frame(i, v.df[[i]]))
  }
  colnames(x) <- c("samp", "class", "pct")
  x <- reshape(x, idvar = "samp", timevar = "class", direction = "wide")
  x[is.na(x)] <- 0 
  rownames(x) <- c(43:1)
  write.csv(x, file = sprintf("Current Data/merg_pct/2021_new/%d_merg_pct.csv", yr))
  print (yr)  
}

######## Get Counts of pixels for cover #####################
for(yr in 1984:2020){
  file <- sprintf("RS Image/The Final Maps/%d_class_final.img", yr)
  r <- raster(file)
  v <- raster::extract(r, buf)
  v.counts <- (lapply(v,table))
  v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
  v.df <- lapply(v.counts , data.frame)
  x <- NULL
  for(i in 1:length(v.df)){
    # row-bind the running df with the table made into a df, and
    #also prepend column "reach" with current iteration
    x <- rbind(x, data.frame(i, v.df[[i]]))
  }
  colnames(x) <- c("reach", "class", "pix")
  x <- reshape(x, idvar = "reach", timevar = "class", direction = "wide")
  x[is.na(x)] <- 0
  write.csv(x, file = sprintf("Current Data/buf_count/2021_new/%d_buf_cnt.csv", yr))
  print(yr)
}

for(yr in 1984:2020){
  file <- sprintf("RS Image/The Final Maps/%d_class_final.img", yr)
  r <- raster(file)
  v <- raster::extract(r, fldpln)
  v.counts <- (lapply(v,table))
  v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
  v.df <- lapply(v.counts , data.frame)
  x <- NULL
  for(i in 1:length(v.df)){
    # row-bind the running df with the table made into a df, and
    #also prepend column "reach" with current iteration
    x <- rbind(x, data.frame(i, v.df[[i]]))
  }
  colnames(x) <- c("reach", "class", "pix")
  x <- reshape(x, idvar = "reach", timevar = "class", direction = "wide")
  x[is.na(x)] <- 0
  write.csv(x, file = sprintf("Current Data/fldpln_count/2021_new/%d_fldpln_cnt.csv", yr))
  print(yr)
}

reach = c(43:1)
for(yr in 1984:2020){
  file <- sprintf("Current Data/buf_count/%d_buf_cnt.csv", yr)
  buf <- read.csv(file, header = TRUE) 
  file <- sprintf("Current Data/fldpln_count/%d_fldpln_cnt.csv", yr)
  fld <- read.csv(file, header = TRUE) 
  buf <- buf[,-c(1:2)]
  fld <- fld[,-c(1:2)]
  buf <- buf[,order (names(buf))]
  fld <- fld[,order (names(fld))]
  mrg <- buf+fld
  mrg <- cbind(reach,mrg)
  write.csv(mrg, file = sprintf("Current Data/mrg_count/%d_mrg_cnt.csv", yr))
}

#######################Frag #################################################
########### frag Metrics###########################################
## Set up  DONE DONE
buf <- readOGR("D:/Dropbox/University Work/Dynamics and Ecology/Current Data/Clipped study area/Buffer_clipped2.shp")
fldpln <- readOGR("D:/Dropbox/University Work/Dynamics and Ecology/Current Data/Clipped study area/fldpln_clipped2.shp")
merg_pln <- readOGR("D:/Dropbox/University Work/Dynamics and Ecology/Current Data/Clipped study area/merged clipped3.shp")
tot_pln <- readOGR("Current Data/Clipped study area/fp_tot_LU.shp")
tot_buf <- readOGR("Current Data/Clipped study area/buf_tot_LU.shp")
projras <- "+proj=utm +zone=12 +ellps=WGS84 +towgs84=0,0,0,-0,-0,-0,0 +units=m +no_def" 
buf <- spTransform(buf, crs(projras))
fldpln <- spTransform(fldpln, crs(projras))
merg_pln <- spTransform(merg_pln, crs(projras))
tot_pln <- spTransform(tot_pln, crs(projras))
tot_buf <- spTransform(tot_buf, crs(projras))

## Set up df
dfbuf <- as.data.frame(buf)
df_fp <- as.data.frame(fldpln)
df_mrg <- as.data.frame(merg_pln)
df_tot_buf <- as.data.frame(tot_buf)
df_tot_pln <- as.data.frame(tot_pln)

#Buffer Perterbation
buffer_frag <- NULL
buffer_frag <- cbind(buffer_frag,sites = as.character(dfbuf[,1]))
buffer_frag <- as.data.frame(buffer_frag)
fld_frag <- NULL
fld_frag <- cbind(fld_frag, sites = as.character(df_fp[,1]))
fld_frag <- as.data.frame(fld_frag)
mrg_frag <- NULL
mrg_frag <- cbind(mrg_frag,sites = as.character(df_mrg[,1]))
mrg_frag <- as.data.frame(mrg_frag)
tot_buf_frag <- NULL
tot_buf_frag <- cbind(tot_buf_frag,sites = as.character(df_tot_buf[,1]))
tot_buf_frag <- as.data.frame(tot_buf_frag)
tot_pln_frag <- NULL
tot_pln_frag <- cbind(tot_pln_frag,sites = as.character(df_tot_pln[,1]))
tot_pln_frag <- as.data.frame(tot_pln_frag)

#set up for Sub the color value with the index score.
value <- c(0, 1, 3, 5, 9, 17, 33, 35, 37, 65, 67, 69, 100, 101, 103, 105, 109, 117, 133, 135, 137, 165, 167, 169)
score <- c(0, 0.4, 0.8, 0.8, 0.2, 1, 0.6, 0.8, 0.6, 0.6, 0.8, 0.6, 0, 0.4, 0.8, 0.8, 0.2, 1, 0.6, 0.8, 0.6, 0.6, 0.8, 0.6)
rcldf <- data.frame(value, score)

#set up score range matrix
buf_score <- c(1:19*0)
rip_score <- c(1:19*0)

#are the parameters.
projras <- "+proj=utm +zone=12 +datum=WGS84 +units=m +no_defs" 


######run em####
#wd needs to change!
wd <- setwd("D:/Dropbox/University Work/Dynamics and Ecology/Current Data/Frag")
yr <- 1984
for(yr in 1984:2020){
  file<-sprintf("D:/Dropbox/University Work/Dynamics and Ecology/RS Image/The Final Maps/%d_class_final.img", yr)
  frag <- raster(file)
  
  #binary map has to have 2 for natural and 1 for human and 0 for NA
  frag[is.na(frag)] <- 0
  frag[frag == 1] <- 2
  frag[frag == 2] <- 2
  frag[frag == 4] <- 2
  frag[frag == 5] <- 2
  frag[frag == 6] <- 2
  frag[frag == 7] <- 2
  frag[frag == 8] <- 2
  frag[frag == 10] <- 1
  frag[frag == 11] <- 1
  frag[frag == 12] <- 2
  frag[frag == 13] <- 2
  frag[frag == 15] <- 1
  
  writeRaster(frag, filename="bin.tif", datatype='INT1U', format="GTiff", overwrite = T)
  bin <- frag
  
  #Model calls from wd
  model <- ('mspa_win64.exe -i bin.tif -o bin_out.tif  -eew 1 -odir "Frag_out/" -transition 1')
  system(model)
  out <- raster("Frag_out/bin_out.tif")
  projection(out) <- projras
  
  ###For 2006###
  xmin(out) <- 231180
  xmax(out) <- 275850
  ymin(out) <- 5330010
  ymax(out) <- 5478630
  
  #sub the color value with scores
  sub <-subs(out, rcldf, by=1, which = 2, subsWithNA=T)
  print(yr)
  writeRaster(sub, filename=sprintf("frag maps/%d_frag.img", yr), overwrite=TRUE)
}

#####################Frag Numbers######################
## Reset WD
wd <-setwd("D:/Dropbox/University Work/Dynamics and Ecology")

buffer_frag <- NULL
buffer_frag <- cbind(buffer_frag,sites = as.character(dfbuf[,1]))
buffer_frag <- as.data.frame(buffer_frag)
fld_frag <- NULL
fld_frag <- cbind(fld_frag, sites = as.character(df_fp[,1]))
fld_frag <- as.data.frame(fld_frag)
mrg_frag <- NULL
mrg_frag <- cbind(mrg_frag,sites = as.character(df_mrg[,1]))
mrg_frag <- as.data.frame(mrg_frag)
tot_buf_frag <- NULL
tot_buf_frag <- cbind(tot_buf_frag,sites = as.character(df_tot_buf[,1]))
tot_buf_frag <- as.data.frame(tot_buf_frag)
tot_pln_frag <- NULL
tot_pln_frag <- cbind(tot_pln_frag,sites = as.character(df_tot_pln[,1]))
tot_pln_frag <- as.data.frame(tot_pln_frag)


for(yr in 1984:2020){
  file<-sprintf("Current Data/Frag/frag maps/%d_frag.img", yr)
  frag <- raster(file) 
  projection(frag) <- projras
  xmin(frag) <- 231180
  xmax(frag) <- 275850
  ymin(frag) <- 5330010
  ymax(frag) <- 5478630
  
  #Buffer Perterbation
  fragb_score <- raster::extract(frag, buf, fun=mean)
  buffer_frag <- cbind(buffer_frag, fragb_score)
  #  colnames(buffer_frag)[colnames(buffer_frag)=="yr"] <- as.character(yr)
  #Floodplain Perterbation
  fragr_score <- raster::extract(frag, fldpln, fun=mean)
  fld_frag <- cbind(fld_frag, fragr_score)
  #  colnames(fld_frag)[colnames(fld_frag)=="yr"] <- as.character(yr)
  #merged Perterbation
  #  fragm_score <- raster::extract(frag, merg_pln, fun=mean)
  #  mrg_frag <- cbind(mrg_frag, fragm_score)
  print(yr)
  #  colnames(mrg_frag)[colnames(mrg_frag)=="yr"] <- as.character(yr)
}

colnames(fld_frag) <- c("Site", c(1984:2020))
colnames(buffer_frag) <- c("Site", c(1984:2020))

### For the 19-20 add on ###
#fldflg <- read.csv(file = 'D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/Reaches/Floodplain_frag.csv')
#buflg <- read.csv(file = 'D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/Reaches/buffer_site_frag.csv')

#fld_frag <- cbind(fldflg, fld_frag[,-1])
#buffer_frag <- cbind(buflg, buffer_frag[,-1])
#####

colnames(mrg_frag) <- c("Site", c(1984:2018))
write.csv(fld_frag, "D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/Reaches/Floodplain_frag.csv")
write.csv(buffer_frag, "D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/Reaches/buffer_site_frag.csv")
#write.csv(mrg_frag, "D:/Dropbox/University Work/Dynamics and Ecology/Current Data/Metrics/mrg_frag.csv")

##### total river #####
wd <-setwd("D:/Dropbox/University Work/Dynamics and Ecology")

for(yr in 2019:2020){
  file<-sprintf("Current Data/Frag/frag maps/%d_frag.img", yr)
  frag <- raster(file) 
  projection(frag) <- projras
  xmin(frag) <- 231180
  xmax(frag) <- 275850
  ymin(frag) <- 5330010
  ymax(frag) <- 5478630
  
  #Buffer Perterbation
  fragb_score <- raster::extract(frag, tot_buf, fun=mean)
  tot_buf_frag <- cbind(tot_buf_frag, fragb_score)
  colnames(tot_buf_frag)[colnames(tot_buf_frag)=="yr"] <- as.character(yr)
  #Floodplain Perterbation
  fragr_score <- raster::extract(frag, tot_pln, fun=mean)
  tot_pln_frag <- cbind(tot_pln_frag, yr = fragr_score)
  colnames(tot_pln_frag)[colnames(tot_pln_frag)=="yr"] <- as.character(yr)
  
}
colnames(tot_pln_frag) <- c("Site", c(2019:2020))
colnames(tot_buf_frag) <- c("Site", c(2019:2020))

### For the 19-20 add on ###
fldflg <- read.csv(file = 'D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/Whole River/Tot_Floodplain_frag.csv')
buflg <- read.csv(file = 'D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/Whole River/tot_buffer_site_frag.csv')

tot_pln_frag <- cbind(fldflg, tot_pln_frag[,-1])
tot_buf_frag <- cbind(buflg, tot_buf_frag[,-1])
#####


write.csv(tot_pln_frag, "D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/Whole River/Tot_Floodplain_frag.csv")
write.csv(tot_buf_frag, "D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/Whole River/tot_buffer_site_frag.csv")

################## Frag Patch count ##############
for(yr in 2019:2020){
  file <- sprintf("Current Data/Frag/frag maps/%d_frag.img", yr)
  r <- raster(file)  
  v <- raster::extract(r, fldpln)
  v.counts <- (lapply(v,table))
  v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
  v.df <- lapply(v.counts , data.frame)
  x <- NULL
  for(i in 1:length(v.df)){
    # row-bind the running df with the table made into a df, and 
    #also prepend column "reach" with current iteration
    x <- rbind(x, data.frame(i, v.df[[i]]))
  }
  colnames(x) <- c("reach", "class", "pix")
  x <- reshape(x, idvar = "reach", timevar = "class", direction = "wide")
  x[is.na(x)] <- 0 
  reach <- x[,1]
  x <- x[,-1]
  x<- x[ , order(names(x))]
  x <- cbind(reach,x)
  colnames(x) <- c("reach", "mangd", "island", "pen", "bridge", "edge", "core")
  write.csv(x, file = sprintf("Current Data/Frag/Frag_count/fldpln_count/%d_fldpln_frag_cnt.csv", yr))
  print (yr)
}


for(yr in 2019:2020){
  file <- sprintf("Current Data/Frag/frag maps/%d_frag.img", yr)
  r <- raster(file)  
  v <- raster::extract(r, buf)
  v.counts <- (lapply(v,table))
  v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
  v.df <- lapply(v.counts , data.frame)
  x <- NULL
  for(i in 1:length(v.df)){
    # row-bind the running df with the table made into a df, and 
    #also prepend column "reach" with current iteration
    x <- rbind(x, data.frame(i, v.df[[i]]))
  }
  colnames(x) <- c("reach", "class", "pix")
  x <- reshape(x, idvar = "reach", timevar = "class", direction = "wide")
  x[is.na(x)] <- 0 
  reach <- x[,1]
  x <- x[,-1]
  x<- x[ , order(names(x))]
  x <- cbind(reach,x)
  colnames(x) <- c("reach", "mangd", "island", "pen", "bridge", "edge", "core")
  write.csv(x, file = sprintf("Current Data/Frag/Frag_count/buf_count/%d_buf_cnt.csv", yr))
  print (yr)
}


`# for(yr in 1984:2018){
#   file <- sprintf("Current Data/Frag/frag maps/%d_frag.img", yr)
#   r <- raster(file)  
#   v <- raster::extract(r, merg_pln)
#   v.counts <- (lapply(v,table))
#   v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
#   v.df <- lapply(v.counts , data.frame)
#   x <- NULL
#   for(i in 1:length(v.df)){
#     # row-bind the running df with the table made into a df, and 
#     #also prepend column "reach" with current iteration
#     x <- rbind(x, data.frame(i, v.df[[i]]))
#   }
#   colnames(x) <- c("reach", "class", "pix")
#   x <- reshape(x, idvar = "reach", timevar = "class", direction = "wide")
#   x[is.na(x)] <- 0 
#   reach <- x[,1]
#   x <- x[,-1]
#   x<- x[ , order(names(x))]
#   x <- cbind(reach,x)
#   colnames(x) <- c("reach", "mangd", "island", "pen", "bridge", "edge", "core")
#   write.csv(x, file = sprintf("Current Data/Frag/Frag_count/mrg_count/%d_mrg_cnt.csv", yr))
#   yr <- yr+1
# }`1

##########Count cover By class all sites all years######################################################

pct <- read.csv("Current Data/fldpln_count/1984_fldpln_cnt.csv", header = TRUE) 
pct <- pct[,-c(1:2)]

for(i in 1:length(pct)){
  pct <- read.csv("Current Data/fldpln_count/1984_fldpln_cnt.csv", header = TRUE) 
  x <- as.data.frame(pct[,1])
  for(yr in 1984:2020){
    file <- sprintf("Current Data/fldpln_count/%d_fldpln_cnt.csv", yr)
    dat <- read.csv(file, header = TRUE) 
    dat <- dat[,-c(1:2)]
    dat <- dat[,order (names(dat))]
    x <- cbind(x, data.frame(dat[,i]))
  }
  colnames(x) <- c("Reach", c(1984:2020))
  write.csv(x, file = sprintf("Current Data/1Total River_Attributes/fld_cnt_class/%s_fld_cnt.csv", colnames(dat)[i]))
}

##buffer##
pct <- read.csv("Current Data/buf_count/1984_buf_cnt.csv", header = TRUE) 
pct <- pct[,-c(1:2)]

for(i in 1:length(pct)){
  pct <- read.csv("Current Data/buf_count/1984_buf_cnt.csv", header = TRUE) 
  x <- as.data.frame(pct[,1])
  for(yr in 1984:2020){
    file <- sprintf("Current Data/buf_count/%d_buf_cnt.csv", yr)
    dat <- read.csv(file, header = TRUE) 
    dat <- dat[,-c(1:2)]
    dat <- dat[,order (names(dat))]
    x <- cbind(x, data.frame(dat[,i]))
  }
  colnames(x) <- c("Reach", c(1984:2020))
  write.csv(x, file = sprintf("Current Data/1Total River_Attributes/buf_cnt_class/%s_buf_cnt.csv", colnames(dat)[i]))
}

#################################Land Use Zones #############################
####################################################
#  Analysis of raster data BY LAND USE ZONES 9/2018#
####################################################

############## Set up site and by buffer by land use zones! ############
#prepping site DF
buf <- readOGR("Current Data/Clipped study area/buf_LU_Zones.shp")
fldpln <- readOGR("Current Data/Clipped study area/fld_LU_Zones.shp")
projras <- "+proj=utm +zone=12 +ellps=WGS84 +towgs84=0,0,0,-0,-0,-0,0 +units=m +no_def" 
buf <- spTransform(buf, crs(projras))
fldpln <- spTransform(fldpln, crs(projras))

## Set up df
dfbuf <- as.data.frame(buf)
df_fp <- as.data.frame(fldpln)

############## frequency and count of cover by site and by buffer over time ############
###Loop through years With three LU buffer data

yr <- 1984
for(yr in 1984:2020){
  file <- sprintf("RS Image/Final_Maps/%d_class_final.img", yr)
  r <- raster(file)  
  v <- raster::extract(r, buf)
  v.counts <- (lapply(v,table))
  v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
  vpct.df <- lapply(v.pct, data.frame)
  vcnt.df <- lapply(v.counts, data.frame)
  xpct <- NULL
  for(i in 1:length(vpct.df)){
    # row-bind the running df with the table made into a df, and 
    #also prepend column "reach" with current iteration
    xpct <- rbind(xpct, data.frame(i, vpct.df[[i]]))
  }
  xcnt <- NULL
  for(i in 1:length(vcnt.df)){
    # row-bind the running df with the table made into a df, and 
    #also prepend column "reach" with current iteration
    xcnt <- rbind(xcnt, data.frame(i, vcnt.df[[i]]))
  }
  colnames(xpct) <- c("samp", "class", "pct")
  colnames(xcnt) <- c("samp", "class", "cnt")
  xpct <- reshape(xpct, idvar = "samp", timevar = "class", direction = "wide")
  xpct[is.na(xpct)] <- 0 
  rownames(xpct) <- c(3:1)
  xcnt <- reshape(xcnt, idvar = "samp", timevar = "class", direction = "wide")
  xcnt[is.na(xcnt)] <- 0 
  rownames(xcnt) <- c(3:1)
  print (yr)
  write.csv(xpct, file = sprintf("Current Data/1Total River_Attributes/LU/pct/%d_LU_buf_pct.csv", yr))
  write.csv(xcnt, file = sprintf("Current Data/1Total River_Attributes/LU/cnt/%d_LU_buf_cnt.csv", yr))
  yr <- yr+1
}

###Loop through years With three LU riparian data
yr <- 1984
jk

######percent cover########
##floodplain##
pct <- read.csv("Current Data/1Total River_Attributes/LU/pct/1984_LU_fldpln_pct.csv", header = TRUE) 
pct <- pct[,-c(1:2)]

for(i in 1:length(pct)){
  pct <- read.csv("Current Data/1Total River_Attributes/LU/pct/1984_LU_buf_pct.csv", header = TRUE) 
  x <- as.data.frame(pct[,1])
  for(yr in 2019:2020){
    file <- sprintf("Current Data/1Total River_Attributes/LU/pct/%d_LU_fldpln_pct.csv", yr)
    dat <- read.csv(file, header = TRUE) 
    dat <- dat[,-c(1:2)]
    dat <- dat[,order (names(dat))]
    x <- cbind(x, data.frame(dat[,i]))
  }
  colnames(x) <- c("Reach", c(2019:2020))
  write.csv(x, file = sprintf("Current Data/1Total River_Attributes/fld_pct_class/%s_lu_fld_pct.csv", colnames(dat)[i]))
}

###buffer##
pct <- read.csv("Current Data/1Total River_Attributes/LU/pct/1984_LU_buf_pct.csv", header = TRUE) 
pct <- pct[,-c(1:2)]

for(i in 1:length(pct)){
  pct <- read.csv("Current Data/1Total River_Attributes/LU/pct/1984_LU_buf_pct.csv", header = TRUE) 
  x <- as.data.frame(pct[,1])
  for(yr in 2019:2020){
    file <- sprintf("Current Data/1Total River_Attributes/LU/pct/%d_LU_buf_pct.csv", yr)
    dat <- read.csv(file, header = TRUE) 
    dat <- dat[,-c(1:2)]
    dat <- dat[,order (names(dat))]
    x <- cbind(x, data.frame(dat[,i]))
  }
  colnames(x) <- c("Reach", c(2019:2020))
  write.csv(x, file = sprintf("Current Data/1Total River_Attributes/buf_pct_class/%s_lu_buf_pct.csv", colnames(dat)[i]))
}



########### frag Metrics###########################################
## Use same set up as above
#Buffer Perturbation
buffer_frag <- NULL
buffer_frag <- cbind(buffer_frag,sites = as.character(dfbuf[,1]))
buffer_frag <- as.data.frame(buffer_frag)
fld_frag <- NULL
fld_frag <- cbind(fld_frag, sites = as.character(df_fp[,1]))
fld_frag <- as.data.frame(fld_frag)

#set up for Sub the color value with the index score.
value <- c(0, 1, 3, 5, 9, 17, 33, 35, 37, 65, 67, 69, 100, 101, 103, 105, 109, 117, 133, 135, 137, 165, 167, 169)
score <- c(0, 0.4, 0.8, 0.8, 0.2, 1, 0.6, 0.8, 0.6, 0.6, 0.8, 0.6, 0, 0.4, 0.8, 0.8, 0.2, 1, 0.6, 0.8, 0.6, 0.6, 0.8, 0.6)
rcldf <- data.frame(value, score)

#set up score range matrix
buf_score <- c(1:19*0)
rip_score <- c(1:19*0)

#are the parameters.
projras <- "+proj=utm +zone=12 +ellps=WGS84 +towgs84=0,0,0,-0,-0,-0,0 +units=m +no_def"

for(yr in 2019:2020){
  file<-sprintf("Current Data/Frag/frag maps/%d_frag.img", yr)
  frag <- raster(file) 
  projection(frag) <- projras
  xmin(frag) <- 231180
  xmax(frag) <- 275850
  ymin(frag) <- 5330010
  ymax(frag) <- 5478630
  #Buffer Perterbation
  fragb_score <- raster::extract(frag, buf, fun=mean)
  buffer_frag <- cbind(buffer_frag, yr = fragb_score)
  colnames(buffer_frag)[colnames(buffer_frag)=="yr"] <- as.character(yr)
  #Floodplain Perterbation
  fragr_score <- raster::extract(frag, fldpln, fun=mean)
  fld_frag <- cbind(fld_frag, yr = fragr_score)
  colnames(fld_frag)[colnames(fld_frag)=="yr"] <- as.character(yr)
  print(yr)
}

### For the 19-20 add on ###
fldflg <- read.csv(file = 'D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/LU/lu_fp_frag.csv')
buflg <- read.csv(file = 'D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/LU/lu_buf_frag.csv')

fld_frag <- cbind(fldflg, fld_frag[,-1])
buffer_frag <- cbind(buflg, buffer_frag[,-1])
#####

write.csv(fld_frag, "D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/LU/lu_fp_frag.csv")
write.csv(buffer_frag, "D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/LU/lu_buf_frag.csv")

################################# Total River #############################
####################################################
#  Analysis of raster data BY Total River          #
####################################################

############## Set up site and by buffer by Total River! ############
#prepping site DF
buf <- readOGR("Current Data/Clipped study area/buf_tot_LU.shp")
fldpln <- readOGR("Current Data/Clipped study area/fp_tot_LU.shp")
projras <- "+proj=utm +zone=12 +ellps=WGS84 +towgs84=0,0,0,-0,-0,-0,0 +units=m +no_def" 
buf <- spTransform(buf, crs(projras))
fldpln <- spTransform(fldpln, crs(projras))

## Set up df
dfbuf <- as.data.frame(buf)
df_fp <- as.data.frame(fldpln)

############## frequency and count of cover by site and by buffer over time ############
###Loop through years With tot buffer data
yr <- 1984
for(yr in 2019:2020){
  file <- sprintf("RS Image/Final_Maps/%d_class_final.img", yr)
  r <- raster(file)  
  v <- raster::extract(r, buf)
  v.counts <- (lapply(v,table))
  v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
  vpct.df <- lapply(v.pct, data.frame)
  vcnt.df <- lapply(v.counts, data.frame)
  xpct <- NULL
  for(i in 1:length(vpct.df)){
    # row-bind the running df with the table made into a df, and 
    #also prepend column "reach" with current iteration
    xpct <- rbind(xpct, data.frame(i, vpct.df[[i]]))
  }
  xcnt <- NULL
  for(i in 1:length(vcnt.df)){
    # row-bind the running df with the table made into a df, and 
    #also prepend column "reach" with current iteration
    xcnt <- rbind(xcnt, data.frame(i, vcnt.df[[i]]))
  }
  colnames(xpct) <- c("samp", "class", "pct")
  colnames(xcnt) <- c("samp", "class", "cnt")
  xpct <- reshape(xpct, idvar = "samp", timevar = "class", direction = "wide")
  xpct[is.na(xpct)] <- 0 
  rownames(xpct) <- 1
  xcnt <- reshape(xcnt, idvar = "samp", timevar = "class", direction = "wide")
  xcnt[is.na(xcnt)] <- 0 
  rownames(xcnt) <- 1
  write.csv(xpct, file = sprintf("Current Data/1Total River_Attributes/total_riv/pct/%d_tot_buf_pct.csv", yr))
  write.csv(xcnt, file = sprintf("Current Data/1Total River_Attributes/total_riv/cnt/%d_tot_buf_cnt.csv", yr))
  print (yr)
}

###Loop through years With tot riparian data
for(yr in 2019:2020){
  file <- sprintf("RS Image/Final_Maps/%d_class_final.img", yr)
  r <- raster(file)  
  v <- raster::extract(r, fldpln)
  v.counts <- (lapply(v,table))
  v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
  vpct.df <- lapply(v.pct, data.frame)
  vcnt.df <- lapply(v.counts, data.frame)
  xpct <- NULL
  for(i in 1:length(vpct.df)){
    # row-bind the running df with the table made into a df, and 
    #also prepend column "reach" with current iteration
    xpct <- rbind(xpct, data.frame(i, vpct.df[[i]]))
  }
  xcnt <- NULL
  for(i in 1:length(vcnt.df)){
    # row-bind the running df with the table made into a df, and 
    #also prepend column "reach" with current iteration
    xcnt <- rbind(xcnt, data.frame(i, vcnt.df[[i]]))
  }
  colnames(xpct) <- c("samp", "class", "pct")
  colnames(xcnt) <- c("samp", "class", "cnt")
  xpct <- reshape(xpct, idvar = "samp", timevar = "class", direction = "wide")
  xpct[is.na(xpct)] <- 0 
  rownames(xpct) <- 1
  xcnt <- reshape(xcnt, idvar = "samp", timevar = "class", direction = "wide")
  xcnt[is.na(xcnt)] <- 0 
  rownames(xcnt) <- 1
  write.csv(xpct, file = sprintf("Current Data/1Total River_Attributes/total_riv/pct/%d_tot_fldpln_pct.csv", yr))
  write.csv(xcnt, file = sprintf("Current Data/1Total River_Attributes/total_riv/cnt/%d_tot_fldpln_cnt.csv", yr))
  print (yr)
}

#######################Class by LU by Year ####################################
######percent cover########
##floodplain##
pct <- read.csv("Current Data/1Total River_Attributes/total_riv/pct/1984_tot_fldpln_pct.csv", header = TRUE) 
pct <- pct[,-c(1:2)]

for(i in 1:length(pct)){
  pct <- read.csv("Current Data/1Total River_Attributes/total_riv/pct/1984_tot_fldpln_pct.csv", header = TRUE) 
  x <- as.data.frame(pct[,1])
  for(yr in 1984:2020){
    file <- sprintf("Current Data/1Total River_Attributes/total_riv/pct/%d_tot_fldpln_pct.csv", yr)
    dat <- read.csv(file, header = TRUE) 
    dat <- dat[,-c(1:2)]
    dat <- dat[,order (names(dat))]
    x <- cbind(x, data.frame(dat[,i]))
  }
  colnames(x) <- c("Reach", c(1984:2020))
  write.csv(x, file = sprintf("Current Data/1Total River_Attributes/total_riv/cnt_class/%s_tot_fld_pct.csv", colnames(dat)[i]))
}

##buffer##
pct <- read.csv("Current Data/1Total River_Attributes/total_riv/pct/1984_tot_buf_pct.csv", header = TRUE) 
pct <- pct[,-c(1:2)]

for(i in 1:length(pct)){
  pct <- read.csv("Current Data/1Total River_Attributes/total_riv/pct/1984_tot_buf_pct.csv", header = TRUE) 
  x <- as.data.frame(pct[,1])
  for(yr in 1984:2020){
    file <- sprintf("Current Data/1Total River_Attributes/total_riv/pct/%d_tot_buf_pct.csv", yr)
    dat <- read.csv(file, header = TRUE) 
    dat <- dat[,-c(1:2)]
    dat <- dat[,order (names(dat))]
    x <- cbind(x, data.frame(dat[,i]))
  }
  colnames(x) <- c("Reach", c(1984:2020))
  write.csv(x, file = sprintf("Current Data/1Total River_Attributes/total_riv/cnt_class/%s_tot_buf_pct.csv", colnames(dat)[i]))
}


######Count cover########
##floodplain##
pct <- read.csv("Current Data/1Total River_Attributes/total_riv/cnt/1984_tot_fldpln_cnt.csv", header = TRUE) 
pct <- pct[,-c(1:2)]

for(i in 1:length(pct)){
  pct <- read.csv("Current Data/1Total River_Attributes/total_riv/cnt/1984_tot_fldpln_cnt.csv", header = TRUE) 
  x <- as.data.frame(pct[,1])
  for(yr in 1984:2020){
    file <- sprintf("Current Data/1Total River_Attributes/total_riv/cnt/%d_tot_fldpln_cnt.csv", yr)
    dat <- read.csv(file, header = TRUE) 
    dat <- dat[,-c(1:2)]
    dat <- dat[,order (names(dat))]
    x <- cbind(x, data.frame(dat[,i]))
  }
  colnames(x) <- c("Reach", c(1984:2020))
  write.csv(x, file = sprintf("Current Data/1Total River_Attributes/total_riv/cnt_class/%s_tot_fld_cnt.csv", colnames(dat)[i]))
}

##buffer##
pct <- read.csv("Current Data/1Total River_Attributes/total_riv/cnt/1984_tot_buf_cnt.csv", header = TRUE) 
pct <- pct[,-c(1:2)]

for(i in 1:length(pct)){
  pct <- read.csv("Current Data/1Total River_Attributes/total_riv/cnt/1984_tot_buf_cnt.csv", header = TRUE) 
  x <- as.data.frame(pct[,1])
  for(yr in 1984:2020){
    file <- sprintf("Current Data/1Total River_Attributes/total_riv/cnt/%d_tot_buf_cnt.csv", yr)
    dat <- read.csv(file, header = TRUE) 
    dat <- dat[,-c(1:2)]
    dat <- dat[,order (names(dat))]
    x <- cbind(x, data.frame(dat[,i]))
  }
  colnames(x) <- c("Reach", c(1984:2020))
  write.csv(x, file = sprintf("Current Data/1Total River_Attributes/total_riv/cnt_class/%s_tot_buf_cnt.csv", colnames(dat)[i]))
}

########### frag Metrics###########################################

## Use same set up as above
## THIS IS DONE ALREADY

#Buffer Perturbation
buffer_frag <- NULL
buffer_frag <- cbind(buffer_frag,sites = as.character(dfbuf[,1]))
buffer_frag <- as.data.frame(buffer_frag)
fld_frag <- NULL
fld_frag <- cbind(fld_frag, sites = as.character(df_fp[,1]))
fld_frag <- as.data.frame(fld_frag)

#set up for Sub the color value with the index score.
value <- c(0, 1, 3, 5, 9, 17, 33, 35, 37, 65, 67, 69, 100, 101, 103, 105, 109, 117, 133, 135, 137, 165, 167, 169)
score <- c(0, 0.4, 0.8, 0.8, 0.2, 1, 0.6, 0.8, 0.6, 0.6, 0.8, 0.6, 0, 0.4, 0.8, 0.8, 0.2, 1, 0.6, 0.8, 0.6, 0.6, 0.8, 0.6)
rcldf <- data.frame(value, score)

#set up score range matrix
buf_score <- c(1:19*0)
rip_score <- c(1:19*0)

#are the parameters.
projras <- "+proj=utm +zone=12 +ellps=WGS84 +towgs84=0,0,0,-0,-0,-0,0 +units=m +no_def" 

#####################Frag Numbers######################
## Reset WD
## ALSO DONE

wd <-setwd("D:/Dropbox/University Work/Dynamics and Ecology")

buffer_frag <- NULL
buffer_frag <- cbind(buffer_frag,sites = as.character(dfbuf[,1]))
buffer_frag <- as.data.frame(buffer_frag)
fld_frag <- NULL
fld_frag <- cbind(fld_frag, sites = as.character(df_fp[,1]))
fld_frag <- as.data.frame(fld_frag)

for(yr in 2019:2020){
  file<-sprintf("Current Data/Frag/frag maps/%d_frag.img", yr)
  frag <- raster(file) 
  projection(frag) <- projras
  xmin(frag) <- 231180
  xmax(frag) <- 275850
  ymin(frag) <- 5330010
  ymax(frag) <- 5478630
  #Buffer Perterbation
  fragb_score <- raster::extract(frag, buf, fun=mean)
  buffer_frag <- cbind(buffer_frag, yr = fragb_score)
  colnames(buffer_frag)[colnames(buffer_frag)=="yr"] <- as.character(yr)
  #Floodplain Perterbation
  fragr_score <- raster::extract(frag, fldpln, fun=mean)
  fld_frag <- cbind(fld_frag, yr = fragr_score)
  colnames(fld_frag)[colnames(fld_frag)=="yr"] <- as.character(yr)
  print (yr)
}
### For the 19-20 add on ###
fldflg <- read.csv(file = 'D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/Whole River/tot_fp_frag.csv')
buflg <- read.csv(file = 'D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/Whole River/tot_buf_frag.csv')

fld_frag <- cbind(fldflg, fld_frag[,-1])
buffer_frag <- cbind(buflg, buffer_frag[,-1])
#####

write.csv(fld_frag, "D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/Whole River/tot_fp_frag.csv")
write.csv(buffer_frag, "D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/Whole River/tot_buf_frag.csv")

#######################################################
################FCI SCORES#############################
#######################################################

########### FCI For all sites, zones and tot ########################################
#anthro <- c(1,1,1,1,1,1,1,0.5,0,1,0.3)
checkn <- matrix(c(1,1,1,1,1,1,1,0.25,0,1,0.5), nrow = 1, ncol = 11)
classes <- c("pct1","pct2","pct4","pct5","pct6","pct7","pct8","pct10","pct11","pct13","pct15")
names(checkn) <- classes
checkn <- checkn[,order (names(checkn))]

## Load and order percent cover of class by year for Floodplain ###
classes <- matrix(c("pct1","pct2","pct4","pct5","pct6","pct7","pct8","pct10","pct11","pct13","pct15"), nrow = 1, ncol = 11)
pct <- read.csv("Current Data/fldpln_pct/1984_fldpln_pct.csv", header = TRUE)
x <- pct[,order (names(pct))]
x<-as.matrix(x)

pert_fp <- x[,1:11]%*%checkn

## Load and order percent cover of class by year for Buffer ###
classes <- matrix(c("pct1","pct2","pct4","pct5","pct6","pct7","pct8","pct10","pct11","pct13","pct15"), nrow = 1, ncol = 11)
buf <- read.csv("Current Data/buf_pct/1984_buf_pct.csv", header = TRUE)
y <- buf[,order (names(buf))]
y<-as.matrix(y)

pert_buf <- y[,1:11]%*%checkn


##########################################
####anthro Metric ########################
####By Site       ########################
##########################################
#######################Run all years ###############################################
buf <- readOGR("D:/Dropbox/University Work/Dynamics and Ecology/Current Data/Clipped study area/Buffer_clipped2.shp")
fldpln <- readOGR("D:/Dropbox/University Work/Dynamics and Ecology/Current Data/Clipped study area/fldpln_clipped2.shp")
projras <- "+proj=utm +zone=12 +ellps=WGS84 +towgs84=0,0,0,-0,-0,-0,0 +units=m +no_def" 
buf <- spTransform(buf, crs(projras))
fldpln <- spTransform(fldpln, crs(projras))

## Set up df
dfbuf <- as.data.frame(buf)
df_fp <- as.data.frame(fldpln)
df_mrg <- as.data.frame(merg_pln)



### Floodplain ###
anthro_met_fp <- df_fp

for(yr in 1984:2020){
  file <- sprintf("Current Data/fldpln_pct/2021_new/%d_fldpln_pct.csv", yr)
  pct <- read.csv(file, header = TRUE)
  x <- pct[,order (names(pct))]
  x <-as.matrix(x)
  pert_fp <- x[,1:11]%*%checkn
  anthro_met_fp <- cbind(anthro_met_fp, pert_fp)
}

names(anthro_met_fp) <- c("sites","area","1984","1985","1986","1987","1988","1989",
                          "1990","1991","1992","1993","1994","1995","1996","1997","1998","1999",
                          "2000","2001","2002","2003","2004","2005","2006","2007","2008","2009",
                          "2010","2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020")

write.csv(anthro_met_fp, file = "Current Data/1Total River_Attributes/Metrics/Reaches/anthro_met_fp21.csv") 

### Buffer ###
anthro_met_buf <- dfbuf

for(yr in 1984:2020){
  file <- sprintf("Current Data/buf_pct/2021_new/%d_buf_pct.csv", yr)
  pct <- read.csv(file, header = TRUE)
  x <- pct[,order (names(pct))]
  x<-as.matrix(x)
  pert_buf <- x[,1:11]%*%checkn
  anthro_met_buf <- cbind(anthro_met_buf, pert_buf)
}

names(anthro_met_buf) <- c("sites","area","1984","1985","1986","1987","1988","1989",
                           "1990","1991","1992","1993","1994","1995","1996","1997","1998","1999",
                           "2000","2001","2002","2003","2004","2005","2006","2007","2008","2009",
                           "2010","2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020")

write.csv(anthro_met_buf, file = "Current Data/1Total River_Attributes/Metrics/Reaches/anthro_met_buf21.csv")  

### merged ###
# anthro_met_mrg <- df_mrg
# 
# for(yr in 2018:2020){
#   file <- sprintf("Current Data/merg_pct/%d_merg_pct.csv", yr)
#   pct <- read.csv(file, header = TRUE)
#   x <- pct[,order (names(pct))]
#   x<-as.matrix(x)
#   pert_mrg <- x[,1:11]%*%checkn
#   anthro_met_mrg<- cbind(anthro_met_mrg, pert_mrg)
#   yr <- yr+1
# }
# 
# names(anthro_met_mrg) <- c("sites","area","1984","1985","1986","1987","1988","1989",
#                           "1990","1991","1992","1993","1994","1995","1996","1997","1998","1999",
#                           "2000","2001","2002","2003","2004","2005","2006","2007","2008","2009",
#                           "2010","2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020")
# 
# write.csv(anthro_met_mrg, file = "Current Data/1Total River_Attributes/Metrics/Reaches/anthro_met_merg.csv") 

##########################################
####anthro Metric ########################
####By LU      ########################
#########################################
#prepping site DF
buf <- readOGR("Current Data/Clipped study area/buf_LU_Zones.shp")
fldpln <- readOGR("Current Data/Clipped study area/fld_LU_Zones.shp")
projras <- "+proj=utm +zone=12 +ellps=WGS84 +towgs84=0,0,0,-0,-0,-0,0 +units=m +no_def" 
buf <- spTransform(buf, crs(projras))
fldpln <- spTransform(fldpln, crs(projras))

## Set up df
dfbuf <- as.data.frame(buf)
df_fp <- as.data.frame(fldpln)

### Floodplain ###
anthro_met_fp <- df_fp

for(yr in 1984:2020){
  file <- sprintf("Current Data/1Total River_Attributes/LU/pct/%d_LU_fldpln_pct.csv", yr)
  pct <- read.csv(file, header = TRUE)
  x <- pct[,order (names(pct))]
  x<-as.matrix(x)
  pert_fp <- x[,1:11]%*%checkn
  anthro_met_fp <- cbind(anthro_met_fp, pert_fp)
  yr <- yr+1
}

names(anthro_met_fp) <- c("sites","area","1984","1985","1986","1987","1988","1989",
                          "1990","1991","1992","1993","1994","1995","1996","1997","1998","1999",
                          "2000","2001","2002","2003","2004","2005","2006","2007","2008","2009",
                          "2010","2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020")

write.csv(anthro_met_fp, file = "Current Data/1Total River_Attributes/Metrics/LU/anthro_met_LU_fp.csv") 

### Buffer ###
anthro_met_buf <- dfbuf

for(yr in 1984:2020){
  file <- sprintf("Current Data/1Total River_Attributes/LU/pct/%d_LU_buf_pct.csv", yr)
  pct <- read.csv(file, header = TRUE)
  x <- pct[,order (names(pct))]
  x<-as.matrix(x)
  pert_buf <- x[,1:11]%*%checkn
  anthro_met_buf <- cbind(anthro_met_buf, pert_buf)
  yr <- yr+1
}

names(anthro_met_buf) <- c("sites","area","1984","1985","1986","1987","1988","1989",
                           "1990","1991","1992","1993","1994","1995","1996","1997","1998","1999",
                           "2000","2001","2002","2003","2004","2005","2006","2007","2008","2009",
                           "2010","2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020")

write.csv(anthro_met_buf, file = "Current Data/1Total River_Attributes/Metrics/LU/anthro_met_LU_buf.csv")  

##########################################
####anthro Metric ########################
####By Total      ########################
#########################################
tot_pln <- readOGR("Current Data/Clipped study area/fp_tot_LU.shp")
tot_buf <- readOGR("Current Data/Clipped study area/buf_tot_LU.shp")
projras <- "+proj=utm +zone=12 +ellps=WGS84 +towgs84=0,0,0,-0,-0,-0,0 +units=m +no_def" 

tot_pln <- spTransform(tot_pln, crs(projras))
tot_buf <- spTransform(tot_buf, crs(projras))

df_tot_buf <- as.data.frame(tot_buf)
df_tot_pln <- as.data.frame(tot_pln)


anthro_met_fp <- df_tot_pln

for(yr in 1984:2020){
  file <- sprintf("Current Data/1Total River_Attributes/total_riv/pct/%d_tot_fldpln_pct.csv", yr)
  pct <- read.csv(file, header = TRUE)
  x <- pct[,order (names(pct))]
  x<-as.matrix(x)
  pert_fp <- x[,1:11]%*%checkn
  anthro_met_fp <- cbind(anthro_met_fp, pert_fp)
  yr <- yr+1
}

names(anthro_met_fp) <- c("sites","area","1984","1985","1986","1987","1988","1989",
                          "1990","1991","1992","1993","1994","1995","1996","1997","1998","1999",
                          "2000","2001","2002","2003","2004","2005","2006","2007","2008","2009",
                          "2010","2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020")

write.csv(anthro_met_fp, file = "Current Data/1Total River_Attributes/Metrics/Whole River/anthro_met_tot_fp.csv") 

### Buffer ###
anthro_met_buf <- df_tot_buf

for(yr in 1984:2020){
  file <- sprintf("Current Data/1Total River_Attributes/total_riv/pct/%d_tot_buf_pct.csv", yr)
  pct <- read.csv(file, header = TRUE)
  x <- pct[,order (names(pct))]
  x<-as.matrix(x)
  pert_buf <- x[,1:11]%*%checkn
  anthro_met_buf <- cbind(anthro_met_buf, pert_buf)
  yr <- yr+1
}

names(anthro_met_buf) <- c("sites","area","1984","1985","1986","1987","1988","1989",
                           "1990","1991","1992","1993","1994","1995","1996","1997","1998","1999",
                           "2000","2001","2002","2003","2004","2005","2006","2007","2008","2009",
                           "2010","2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020")

write.csv(anthro_met_buf, file = "Current Data/1Total River_Attributes/Metrics/Whole River/anthro_met_tot_buf.csv")  


########### FCI #######################################################################################
## Human Disturbance    ## 
## PREP by site, lu, TOT

##See Habitat Code for Most recent version. ##
##########################

## Site ###
buf.frag <- read.csv("Current Data/1Total River_Attributes/Metrics/Reaches/buffer_site_frag.csv", header = TRUE)
buf.pert <- read.csv("Current Data/1Total River_Attributes/Metrics/Reaches/anthro_met_buf.csv", header = TRUE)
rip.frag <- read.csv("Current Data/1Total River_Attributes/Metrics/Reaches/Floodplain_frag.csv", header = TRUE)
rip.pert <- read.csv("Current Data/1Total River_Attributes/Metrics/Reaches/anthro_met_fp.csv", header = TRUE)
## lu ###
lu.buf.frag <- read.csv("Current Data/1Total River_Attributes/Metrics/lu/lu_buf_frag.csv", header = TRUE)
lu.rip.frag <- read.csv("Current Data/1Total River_Attributes/Metrics/lu/lu_fp_frag.csv", header = TRUE)
lu.buf.pert <- read.csv("Current Data/1Total River_Attributes/Metrics/LU/anthro_met_LU_buf.csv", header = TRUE)
lu.rip.pert <- read.csv("Current Data/1Total River_Attributes/Metrics/LU/anthro_met_LU_fp.csv", header = TRUE) 
## tot ###
tot.rip.frag <- read.csv("Current Data/1Total River_Attributes/Metrics/Whole River/tot_fp_frag.csv", header = TRUE)
tot.buf.frag <- read.csv("Current Data/1Total River_Attributes/Metrics/Whole River/tot_buf_frag.csv", header = TRUE)
tot.buf.pert <- read.csv("Current Data/1Total River_Attributes/Metrics/Whole River/anthro_met_tot_buf.csv", header = TRUE)
tot.rip.pert <- read.csv("Current Data/1Total River_Attributes/Metrics/Whole River/anthro_met_tot_fp.csv", header = TRUE) 

## Site###
rip.pert <-rip.pert[,-c(1:3)]
buf.pert <- buf.pert[,-c(1:3)]
buf.frag <- buf.frag[,-c(1:3)]
rip.frag <- rip.frag[,-c(1:3)]

## lu ###
lu.rip.frag <- lu.rip.frag[,-c(1:3)]
lu.buf.frag <- lu.buf.frag[,-c(1:3)]
lu.buf.pert <- lu.buf.pert[,-c(1:3)]
lu.rip.pert <- lu.rip.pert[,-c(1:3)]

## tot ###
tot.buf.pert <- tot.buf.pert[,-c(1:3)]
tot.rip.pert <- tot.rip.pert[,-c(1:3)]
tot.rip.frag <- tot.rip.frag[,-c(1:3)]
tot.buf.frag <- tot.buf.frag[,-c(1:3)]

yrs <- c(1984:2020)

###By Site
tim.index <- ((((buf.frag + buf.pert)/2)+rip.frag+rip.pert)/3)

avg.frag <- (buf.frag + rip.frag)/2
avg.pert <- (buf.pert + rip.pert)/2

names(tim.index) <- yrs
names(avg.frag) <- yrs
names(avg.pert) <- yrs

write.csv(tim.index, "Current Data/FCI/human_impact.csv")
write.csv(avg.frag, "Current Data/FCI/avg_frag.csv")
write.csv(avg.pert, "Current Data/FCI/avg_pert.csv")

### Land use
LU.index <- ((((lu.buf.frag + lu.buf.pert)/2)+lu.rip.frag+lu.rip.pert)/3)

avg.frag <- (lu.buf.frag + lu.rip.frag)/2
avg.pert <- (lu.buf.pert + lu.rip.pert)/2

write.csv(LU.index, "Current Data/FCI/LU_anthro.csv")
write.csv(avg.frag, "Current Data/FCI/LU_avg_frag.csv")
write.csv(avg.pert, "Current Data/FCI/LU_avg_pert.csv")

###Tot River
LU.index <- ((((tot.buf.frag + tot.buf.pert)/2)+tot.rip.frag+tot.rip.pert)/3)

avg.frag <- (tot.buf.frag + tot.rip.frag)/2
avg.pert <- (tot.buf.pert + tot.rip.pert)/2

write.csv(LU.index, "Current Data/FCI/tot_anthro.csv")
write.csv(avg.frag, "Current Data/FCI/tot_avg_frag.csv")
write.csv(avg.pert, "Current Data/FCI/tot_avg_pert.csv")

################ Save all the work##################

save.image(file = "D:/Dropbox/University Work/Dynamics and Ecology/Current data/summary data2.RData")


# Section 6 Application of Portfolio analysis.  ---------------------------

#### At this point all classification is complete and are stored in 
#### RS Image/The Final Maps. The following code sets up the base data to
#### do the analysis for the metrics. This requires the percent cover of each 
#### class and the count of pixels per class. These are done for both the 
#### floodplain and buffer ####

#prepping site DF
merg_pln <- readOGR("GIS Background/2021/mrg_UTM12.shp")
buf <- readOGR("GIS Background/2021/buf_utm12.shp")
fldpln <- readOGR("GIS Background/2021/flp_UTM12.shp")

## Set up df
dfbuf <- as.data.frame(buf)
df_fp <- as.data.frame(fldpln)
df_mrg <- as.data.frame(merg_pln)

############## frequency of cover by reach over time ############
###Loop through years With buffer data
yr <- 1984
for(yr in 1984:2020){
  file <- sprintf("RS Image/The Final Maps/%d_class_final.img", yr)
  r <- raster(file)  
  flood = NULL
  x=1
  while(x<45){
    v <- raster::extract(r, buf[buf$confluvid == x,])
    flood <- rbind(flood,v)
    x<-x+1
  }
  v.counts <-(lapply(flood,table))
  v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
  p.df <- lapply(v.pct, data.frame)
  c.df <- lapply(v.counts , data.frame)
  p <- NULL
  c <- NULL
  for(j in 1:length(p.df)){
    # row-bind the running df with the table made into a df, and 
    #also prepend column "reach" with current iteration
    p <- rbind(p, data.frame(j, p.df[[j]]))
    c <- rbind(c, data.frame(j, c.df[[j]]))
  }
  colnames(p) <- c("samp", "class", "pct")
  colnames(c) <- c("samp", "class", "cnt")
  p <- reshape(p, idvar = "samp", timevar = "class", direction = "wide")
  c <- reshape(c, idvar = "samp", timevar = "class", direction = "wide")
  p[is.na(p)] <- 0 
  c[is.na(c)] <- 0
  write.csv(p, file = sprintf("Current Data/buf_pct/2021_new/%d_buf_pct.csv", yr))
  write.csv(c, file = sprintf("Current Data/buf_count/2021_new/%d_buf_cnt.csv", yr))
  print (yr)
  yr <- yr+1
}

###Loop through years With riparian data
yr <- 1984
for(yr in 1984:2020){
  file <- sprintf("RS Image/The Final Maps/%d_class_final.img", yr)
  r <- raster(file)  
  flood = NULL
  x=1
  while(x<45){
    v <- raster::extract(r, fldpln[fldpln$sites == x,])
    flood <- rbind(flood,v)
    x<-x+1
  }
  v.counts <- (lapply(flood,table))
  v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
  p.df <- lapply(v.pct, data.frame)
  c.df <- lapply(v.counts , data.frame)
  p <- NULL
  c <- NULL
  for(j in 1:length(p.df)){
    # row-bind the running df with the table made into a df, and 
    #also prepend column "reach" with current iteration
    p <- rbind(p, data.frame(j, p.df[[j]]))
    c <- rbind(c, data.frame(j, c.df[[j]]))
  }
  colnames(p) <- c("samp", "class", "pct")
  colnames(c) <- c("samp", "class", "cnt")
  p <- reshape(p, idvar = "samp", timevar = "class", direction = "wide")
  c <- reshape(c, idvar = "samp", timevar = "class", direction = "wide")
  p[is.na(p)] <- 0 
  c[is.na(c)] <- 0
  write.csv(p, file = sprintf("Current Data/fldpln_pct/2021_new/%d_fldpln_pct.csv", yr))
  write.csv(c, file = sprintf("Current Data/fldpln_count/2021_new/%d_fldpln_cnt.csv", yr))
  print (yr)
  yr <- yr+1
}

yr <- 1984
for(yr in 1984:2020){
  file <- sprintf("RS Image/The Final Maps/%d_class_final.img", yr)
  r <- raster(file) 
  flood = NULL
  x=1
  while(x<45){
    v <- raster::extract(r, merg_pln[merg_pln$confluvid == x,])
    flood <- rbind(flood,v)
    x<-x+1
  }
  v.counts <- (lapply(flood,table))
  v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
  v.df <- lapply(v.pct, data.frame)
  x <- NULL
  for(i in 1:length(v.df)){
    # row-bind the running df with the table made into a df, and 
    #also prepend column "reach" with current iteration
    x <- rbind(x, data.frame(i, v.df[[i]]))
  }
  colnames(x) <- c("samp", "class", "pct")
  x <- reshape(x, idvar = "samp", timevar = "class", direction = "wide")
  x[is.na(x)] <- 0 
  write.csv(x, file = sprintf("Current Data/merg_pct/2021_new/%d_merg_pct.csv", yr))
  print (yr)  
}

############## frequency of cover by reach over time ############
######## Get Counts of pixels for cover #####################
# for(yr in 1984:2020){
#   file <- sprintf("RS Image/The Final Maps/%d_class_final.img", yr)
#   r <- raster(file)
#   v <- raster::extract(r, buf)
#   v.counts <- (lapply(v,table))
#   v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
#   v.df <- lapply(v.counts , data.frame)
#   x <- NULL
#   for(i in 1:length(v.df)){
#     # row-bind the running df with the table made into a df, and
#     #also prepend column "reach" with current iteration
#     x <- rbind(x, data.frame(i, v.df[[i]]))
#   }
#   colnames(x) <- c("reach", "class", "pix")
#   x <- reshape(x, idvar = "reach", timevar = "class", direction = "wide")
#   x[is.na(x)] <- 0
#   write.csv(x, file = sprintf("Current Data/buf_count/2021_new/%d_buf_cnt.csv", yr))
#   print(yr)
# }
# 
# for(yr in 1984:2020){
#   file <- sprintf("RS Image/The Final Maps/%d_class_final.img", yr)
#   r <- raster(file)
#   v <- raster::extract(r, fldpln)
#   v.counts <- (lapply(v,table))
#   v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
#   v.df <- lapply(v.counts , data.frame)
#   x <- NULL
#   for(i in 1:length(v.df)){
#     # row-bind the running df with the table made into a df, and
#     #also prepend column "reach" with current iteration
#     x <- rbind(x, data.frame(i, v.df[[i]]))
#   }
#   colnames(x) <- c("reach", "class", "pix")
#   x <- reshape(x, idvar = "reach", timevar = "class", direction = "wide")
#   x[is.na(x)] <- 0
#   write.csv(x, file = sprintf("Current Data/fldpln_count/2021_new/%d_fldpln_cnt.csv", yr))
#   print(yr)
# }
# 
# #### Following this set up, we are now ready to calculate metrics. First
#### are measures of diversity. The ecofolio paper uses Vegan's Simpson's D, 
#### which outputs a value between 0-1 with zero being no diversity. ####

############## Simpson's D metric (and others) ############
## Set up df
dfbuf <- as.data.frame(buf)
dfbuf$site <- c(1:44)
dfbuf<-dfbuf[-c(1:4)]


### Load in pixel counts
nam <- c("sites", "1984","1985","1986","1987","1988","1989",
         "1990","1991","1992","1993","1994","1995","1996","1997","1998","1999",
         "2000","2001","2002","2003","2004","2005","2006","2007","2008","2009",
         "2010","2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020")

div_h <- dfbuf
div_d <- dfbuf
div_inv <- dfbuf

for(yr in 1984:2020){
  file <- sprintf("Current Data/fldpln_count/2021_new/%d_fldpln_cnt.csv", yr)
  pct <- read.csv(file, header = TRUE)
  x <- pct[,order (names(pct))]
  x <-as.matrix(x)
  H <-diversity(x[,c(1,4,6,7,8,9,10,11)],index = "shannon") 
  D <-diversity(x[,c(1,4,6,7,8,9,10,11)],index = "simpson")
  inv <-diversity(x[,c(1,4,6,7,8,9,10,11)],index = "invsimpson")  
  
  div_h <- cbind(div_h, H)
  div_d <- cbind(div_d, D) 
  div_inv <- cbind(div_inv, inv) 
  yr <- yr+1
}

colnames(div_h) <- nam
colnames(div_d) <- nam
colnames(div_inv) <- nam

write.csv(div_h, file = "Current Data/1Total River_Attributes/Metrics/Reaches/div_fldpln_shannon21.csv") 
write.csv(div_d, file = "Current Data/1Total River_Attributes/Metrics/Reaches/div_fldpln_simpson21.csv") 
write.csv(div_inv, file = "Current Data/1Total River_Attributes/Metrics/Reaches/div_fldpln_invsimpson21.csv") 

### Buffer ###
div_h <- dfbuf
div_d <- dfbuf
div_inv <- dfbuf

for(yr in 1984:2020){
  file <- sprintf("Current Data/buf_count/2021_new/%d_buf_cnt.csv", yr)
  pct <- read.csv(file, header = TRUE)
  x <- pct[,order (names(pct))]
  x <-as.matrix(x)
  H <-diversity(x[,c(1,4,6,7,8,9,10,11)],index = "shannon") 
  D <-diversity(x[,c(1,4,6,7,8,9,10,11)],index = "simpson")
  inv <-diversity(x[,c(1,4,6,7,8,9,10,11)],index = "invsimpson")  
  div_h <- cbind(div_h, H)
  div_d <- cbind(div_d, D) 
  div_inv <- cbind(div_inv, inv)  
  yr <- yr+1
}

colnames(div_h) <- nam
colnames(div_d) <- nam
colnames(div_inv) <- nam

write.csv(div_h, file = "Current Data/1Total River_Attributes/Metrics/Reaches/div_buf_shannon21.csv") 
write.csv(div_d, file = "Current Data/1Total River_Attributes/Metrics/Reaches/div_buf_simpson21.csv") 
write.csv(div_inv, file = "Current Data/1Total River_Attributes/Metrics/Reaches/div_buf_invsimpson21.csv")

##########################################################################
#### Second are measures of anthropologically altered vegetation. #### 
###########################################################################

############## Anthro set up ############
checkn <- matrix(c(1,1,1,1,1,1,1,0.25,0,1,0.5), nrow = 1, ncol = 11)
classes <- c("pct1","pct2","pct4","pct5","pct6","pct7","pct8","pct10","pct11","pct13","pct15")
names(checkn) <- classes
checkn <- checkn[,order (names(checkn))]

## Load and order percent cover of class by year for Floodplain ###
classes <- matrix(c("pct1","pct2","pct4","pct5","pct6","pct7","pct8","pct10","pct11","pct13","pct15"), nrow = 1, ncol = 11)
pct <- read.csv("Current Data/fldpln_pct/2021_new/1984_fldpln_pct.csv", header = TRUE)
x <- pct[,order (names(pct))]
x<-as.matrix(x)

pert_fp <- x[,1:11]%*%checkn

## Load and order percent cover of class by year for Buffer ###
classes <- matrix(c("pct1","pct2","pct4","pct5","pct6","pct7","pct8","pct10","pct11","pct13","pct15"), nrow = 1, ncol = 11)
buf <- read.csv("Current Data/buf_pct/2021_new/1984_buf_pct.csv", header = TRUE)
y <- buf[,order (names(buf))]
y<-as.matrix(y)

pert_buf <- y[,1:11]%*%checkn

################## Anthro Metric##################
#prepping site DF
dfbuf <- as.data.frame(buf)
dfbuf$site <- c(1:44)
dfbuf<-dfbuf[-c(1:4)]

### Floodplain ###
anthro_met_fp <- dfbuf

for(yr in 1984:2020){
  file <- sprintf("Current Data/fldpln_pct/2021_new/%d_fldpln_pct.csv", yr)
  pct <- read.csv(file, header = TRUE)
  x <- pct[,order (names(pct))]
  x <-as.matrix(x)
  pert_fp <- x[,1:11]%*%checkn
  anthro_met_fp <- cbind(anthro_met_fp, pert_fp)
}

names(anthro_met_fp) <- c("sites","1984","1985","1986","1987","1988","1989",
                          "1990","1991","1992","1993","1994","1995","1996","1997","1998","1999",
                          "2000","2001","2002","2003","2004","2005","2006","2007","2008","2009",
                          "2010","2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020")

write.csv(anthro_met_fp, file = "Current Data/1Total River_Attributes/Metrics/Reaches/anthro_met_fp21.csv") 

### Buffer ###
anthro_met_buf <- dfbuf

for(yr in 1984:2020){
  file <- sprintf("Current Data/buf_pct/2021_new/%d_buf_pct.csv", yr)
  pct <- read.csv(file, header = TRUE)
  x <- pct[,order (names(pct))]
  x<-as.matrix(x)
  pert_buf <- x[,1:11]%*%checkn
  anthro_met_buf <- cbind(anthro_met_buf, pert_buf)
}

names(anthro_met_buf) <- c("sites","1984","1985","1986","1987","1988","1989",
                           "1990","1991","1992","1993","1994","1995","1996","1997","1998","1999",
                           "2000","2001","2002","2003","2004","2005","2006","2007","2008","2009",
                           "2010","2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020")

write.csv(anthro_met_buf, file = "Current Data/1Total River_Attributes/Metrics/Reaches/anthro_met_buf21.csv")  

##########################################################################
#### Third are measures of fragmentation of the landscape. #### 
###########################################################################
## Set up df
buf <- readOGR("GIS Background/2021/buf_utm12.shp")
fldpln <- readOGR("GIS Background/2021/flp_UTM12.shp")

dfbuf <- as.data.frame(buf)
df_fp <- as.data.frame(fldpln)

#Buffer Perturbation
buffer_frag <- NULL
buffer_frag <- cbind(buffer_frag,sites = as.character(dfbuf[,1]))
buffer_frag <- as.data.frame(buffer_frag)
fld_frag <- NULL
fld_frag <- cbind(fld_frag, sites = as.character(df_fp[,1]))
fld_frag <- as.data.frame(fld_frag)

#set up for Sub the color value with the index score.
value <- c(0, 1, 3, 5, 9, 17, 33, 35, 37, 65, 67, 69, 100, 101, 103, 105, 109, 117, 133, 135, 137, 165, 167, 169)
score <- c(0, 0.4, 0.8, 0.8, 0.2, 1, 0.6, 0.8, 0.6, 0.6, 0.8, 0.6, 0, 0.4, 0.8, 0.8, 0.2, 1, 0.6, 0.8, 0.6, 0.6, 0.8, 0.6)
rcldf <- data.frame(value, score)

#set up score range matrix
buf_score <- c(1:19*0)
rip_score <- c(1:19*0)

#################################################
######run all the previous classified scenes ####
###################################################
#wd needs to change!
wd <- setwd("D:/Dropbox/University Work/Dynamics and Ecology/Current Data/Frag")
projras <- "+proj=utm +zone=12 +datum=WGS84 +units=m +no_defs" 
yr<-1984

for(yr in 1984:2020){
  file<-sprintf("D:/Dropbox/University Work/Dynamics and Ecology/RS Image/The Final Maps/%d_class_final.img", yr)
  frag <- raster(file)
  
  #binary map has to have 2 for natural and 1 for human and 0 for NA
  frag[is.na(frag)] <- 0
  frag[frag == 1] <- 2
  frag[frag == 2] <- 2
  frag[frag == 4] <- 2
  frag[frag == 5] <- 2
  frag[frag == 6] <- 2
  frag[frag == 7] <- 2
  frag[frag == 8] <- 2
  frag[frag == 10] <- 1
  frag[frag == 11] <- 1
  frag[frag == 12] <- 2
  frag[frag == 13] <- 2
  frag[frag == 15] <- 1
  
  writeRaster(frag, filename="bin.tif", datatype='INT1U', format="GTiff", overwrite = T)
  bin <- frag
  
  #Model calls from wd
  model <- ('mspa_win64.exe -i bin.tif -o bin_out.tif  -eew 1 -odir "Frag_out/" -transition 1')
  system(model)
  out <- raster("Frag_out/bin_out.tif")
  projection(out) <- projras
  xmin(out) <- 225210
  xmax(out) <- 281820
  ymin(out) <- 5329260
  ymax(out) <- 5479380
  # 
  #sub the color value with scores
  sub <-subs(out, rcldf, by=1, which = 2, subsWithNA=T)
  print(yr)
  writeRaster(sub, filename=sprintf("Current Data/Frag/frag maps/%d_frag.img", yr), overwrite=TRUE)
}

######################################################
#####################Frag Metric ######################
#####################################################

## Reset WD
wd <-setwd("D:/Dropbox/University Work/Dynamics and Ecology")

buffer_frag <- NULL
buffer_frag <- cbind(buffer_frag,sites = as.character(dfbuf[,1]))
buffer_frag <- as.data.frame(buffer_frag)
fld_frag <- NULL
fld_frag <- cbind(fld_frag, sites = as.character(dfbuf[,1]))
fld_frag <- as.data.frame(fld_frag)

yr<-1984

for(yr in 1984:2020){
  file<-sprintf("Current Data/Frag/frag maps/%d_frag.img", yr)
  frag <- raster(file) 
  
  #Buffer Perturbation
  fragb_score = NULL
  x=1
  while(x<45){
    duh <- raster::extract(frag, buf[buf$confluvid == x,], fun=mean, df=TRUE)
    fragb_score <- rbind(fragb_score,duh)
    x<-x+1
  }
  buffer_frag <- cbind(buffer_frag, fragb_score[,2])
  fragr_score = NULL
  x=1
  while(x<45){
    duh <- raster::extract(frag, fldpln[fldpln$sites == x,], fun=mean, df=TRUE)
    fragr_score <- rbind(fragr_score,duh)
    x<-x+1
  }
  fld_frag <- cbind(fld_frag, fragr_score[,2])
  print(yr)
}

colnames(fld_frag) <- c("Site", c(1984:2020))
colnames(buffer_frag) <- c("Site", c(1984:2020))

fld_frag$Site <- c(1:44)
buffer_frag$Site <- c(1:44)


write.csv(fld_frag, "D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/Reaches/Floodplain_frag.csv")
write.csv(buffer_frag, "D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/Reaches/buffer_site_frag.csv")

########################################################################
#### At this point all metrics are scored for all years. Now we move to#
#### calculating MMI scores for all years and plot those #### 
########################################################################

vegb <- read.csv("Current Data/1Total River_Attributes/Metrics/Reaches/anthro_met_buf21.csv")
vegf <- read.csv("Current Data/1Total River_Attributes/Metrics/Reaches/anthro_met_fp21.csv")
simpb <- read.csv("Current Data/1Total River_Attributes/Metrics/Reaches/div_buf_simpson21.csv")
simpf <- read.csv("Current Data/1Total River_Attributes/Metrics/Reaches/div_fldpln_simpson21.csv")
fragb <- read.csv("Current Data/1Total River_Attributes/Metrics/Reaches/buffer_site_frag.csv")
fragf <- read.csv("Current Data/1Total River_Attributes/Metrics/Reaches/Floodplain_frag.csv")

clean <- function (x){
  x <- as.data.frame(t(x))
  x <- x[-c(1:2),]
  yr <- c(1984:2020)
  x <- cbind(yr,x)
  nam <- c("year",c(1:44))
  colnames(x) <- nam
  melt(x, id=c("year"))}

# clean2 <- function (x){
#   x <- as.data.frame(t(x))
#   x <- x[-c(1:2),]
#   yr <- c(1984:2020)
#   x <- cbind(yr,x)
#   nam <- c("year",c(44:1))
#   colnames(x) <- nam
#   melt(x, id=c("year"))}

mvegb <- clean(vegb)
colnames(mvegb) <- c("year","site","vegb")
print(head(mvegb, 5))

mvegf <- clean(vegf)
colnames(mvegf) <- c("year","site","vegf")
print(head(mvegf, 5))

msimpb <- clean(simpb)
colnames(msimpb) <- c("year","site","simpb")
print(head(msimpb, 5))

msimpf <- clean(simpf)
colnames(msimpf) <- c("year","site","simpf")
print(head(msimpf, 5))

mfragb <- clean(fragb)
colnames(mfragb) <- c("year","site","fragb")
print(head(mfragb, 5))

mfragf <- clean(fragf)
colnames(mfragf) <- c("year","site","fragf")
print(head(mfragf, 5))

tot <- NULL
tot <- cbind(mvegb,mvegf[,3])
tot <- cbind(tot,msimpb[,3])
tot <- cbind(tot,msimpf[,3])
tot <- cbind(tot,mfragb[,3])
tot <- cbind(tot,mfragf[,3])
colnames(tot)<- c("year","site","vegb","vegf","simpb","simpf","fragb","fragf")
print(tail(tot, 20))

write.csv(tot, file = ("Current Data/1Total River_Attributes/Metrics/Reaches/hab_met21.csv"))

##########F-n list problem so saved it are reload#
hab <- read.csv("Current Data/1Total River_Attributes/Metrics/Reaches/hab_met21.csv")
hab <-hab[,-1]
hab_sites <-as.data.frame(hab)
print(head(hab, 10))

fci_44 <- NULL
fci<- NULL
fci_44 <- cbind(hab[,1:2])

bc <- (((hab$vegb+hab$simpb)/2+hab$fragb)/2)
fci_44$fci = ((hab$vegf+hab$simpf)/2+hab$fragf+bc)/3

con <-dcast(fci_44, year~site, value.var = 'fci')

x11()
#set margins and get the labels from touching the tick marks
par( mar=c(6, 6, 4, 2) + 0.1 )
par( mgp = c(4,1,0))
boxplot(con[,-1],  las=1,ylab ="Assessment Score", xlab ="Site",  main = "Floodplain Habitat Condition",
        cex.lab=1.5, cex.axis=1.5, cex.main=2.0, cex.sub=1.5)
abline(h=0, lty=3, lwd= 3)
dev.off()

##### average by land use cover across all years ###########################
avguse <- NULL
#avguse$sites <- c(1:44)
avgconfor <- avguse
avgdecfor <- avguse
avgimdec <- avguse
avgshrub <- avguse
avgmed <- avguse
avgpstfir <- avguse
avgcobb <- avguse
avgriv <- avguse
avgnat <- avguse
avgurb <- avguse
avgag <- avguse
avglog <- avguse

for(yr in 1984:2020){
  data <- read.csv(sprintf("Current Data/merg_pct/2021_new/%d_merg_pct.csv", yr), header = TRUE)
  data <- data[order(data[,1]),]
  data <- data[,-1]
  data <- data[order(names(data))]
  
  lu <- data
  avgconfor <- cbind(avgconfor,lu[,c(1)])
  avgdecfor <- cbind(avgdecfor,lu[,c(6)])
  avgimdec <- cbind(avgimdec,lu[,c(7)])
  avgshrub <- cbind(avgshrub,lu[,c(8)])
  avgmed <- cbind(avgmed,lu[,c(9)])
  avgpstfir <- cbind(avgpstfir,lu[,c(4)])
  avgcobb <- cbind(avgcobb,lu[,c(10)])
  avgriv <- cbind(avgriv,lu[,c(11)])
  avgnat <- cbind(avgnat,rowSums(lu[,c(1,4,6,7,8,9,10,11)]))
  avgurb <- cbind(avgurb,lu[,c(3)])
  avgag <- cbind(avgag,lu[,c(2)]) 
  avglog <- cbind(avglog,lu[,c(5)])
}
meanconfor <- rowMeans(avgconfor)
meandecfor <- rowMeans(avgdecfor)
meanimdec <- rowMeans(avgimdec)
meanshrub <- rowMeans(avgshrub)
meanmedo <- rowMeans(avgmed)
meanpstfr <- rowMeans(avgpstfir)
meanvob <- rowMeans(avgcobb)
meanriv <- rowMeans(avgriv)
meannat <- rowMeans(avgnat)
#mednat <- apply(avgnat[,-1], 1, median)   
meanurb <- rowMeans(avgurb)
#medurb <- apply(avgurb[,-1], 1, median)   
meanag <- rowMeans(avgag)
#medag <- apply(avgag[,-1], 1, median)   
meanlog <- rowMeans(avglog)
#medlog <- apply(avglog[,-1], 1, median)   

meanuse <- cbind(data[,12],avguse,meannat, meanurb, meanag, meanlog)
colnames(meanuse) <- c("site", "Natural","Urban", "Agriculture","Logging")

meanuse_all <- cbind(data[,12], avguse, meanconfor, meandecfor, meanimdec, meanshrub, meanmedo, 
                     meanpstfr,meanvob, meanriv, meanurb,  meanag, meanlog)
colnames(meanuse_all) <- c("site", "Mature Conifer","Deciduous Forest","Immature Deciduous",
                           "Shrub","Meadow", "Post Fire","Cobble","River",
                           "Urban", "Agriculture","Logging")

write.csv(meanuse, file = ("Current Data/1Total River_Attributes/Metrics/Reaches/mean_land_use21.csv"))
write.csv(meanuse_all, file = ("Current Data/1Total River_Attributes/Metrics/Reaches/mean_land_use_all21.csv"))

####For ggplot all landuse####

meanuse_all <- read.csv("Current Data/1Total River_Attributes/Metrics/Reaches/mean_land_use_all21.csv")
meanuse_all <- meanuse_all[order(meanuse_all[,1]),]
meanuse_all <- meanuse_all[,-1]
colnames(meanuse_all) <- c("site", "Mature Conifer","Mature Deciduous","Immature Deciduous",
                           "Shrub","Meadow", "Post Fire","Cobble","River",
                           "Urban", "Agriculture","Logging")
rownames(meanuse_all) <- c(1:44)
mdata_all <- melt(meanuse_all[,c(1:12)], id=c("site"))
colnames(mdata_all) <- c("site", "lndcov", "pctcov")

# Stacked + percent for GGPLOT
p <- ggplot(mdata_all, aes(y=pctcov, x=site)) 

p + geom_bar(position="fill", stat="identity", alpha = 0.8, 
             aes(fill=factor(lndcov)), colour = "black") +
  scale_fill_brewer(palette="BrBG", direction=-1)+
  theme_bw() + theme_minimal() +
  
  scale_y_continuous(limits = c(0,1), expand = c(0, 0)) +
  scale_x_continuous(breaks = seq(1,45,2), expand = c(0, 0)) +
  #axis.ticks.length = unit(half_line/2, "pt") 
  theme(text = element_text(size = 20)) + 
  ylab ("Total Cover") +
  xlab ("Sites") +
  theme(legend.position="top",legend.direction = "horizontal") + labs(fill = "Land Use") +
  guides(fill=guide_legend(nrow = 2))

#########################################################################################
#########Now look at the MPT of these data   ############################################
##########################################################################################

hab <- read.csv("D:/Dropbox/University Work/Dynamics and Ecology/Current Data/1Total River_Attributes/Metrics/Reaches/hab_met21.csv")
hab<-hab[,-1]
hab<-as.data.frame(hab)
print(tail(hab, 5))

####################Assets weights ###################################
##########load data by reach#########################

hab_wgt <- (hab[1,-c(1:2)])
hab_wgt[1,] <- c(.08333,.16667,.08333,.16667,.16667,.33333)

#W################ site!#############################
##################set up data table and expected returns ###############################

habdt <- setDT(hab)

# calculate the arithmetic mean of returns
hab_mn <- habdt[, .(vb = mean(vegb), 
                    vf = mean(vegf), 
                    sb = mean(simpb), 
                    sf = mean(simpf), 
                    fb = mean(fragb), 
                    ff = mean(fragf)),
                by = site]

# calculate the SD for returns
hab_sd <- habdt[, .(sd_vb = sd(vegb), 
                    sd_vf = sd(vegf), 
                    sd_sb = sd(simpb), 
                    sd_sf = sd(simpf), 
                    sd_fb = sd(fragb), 
                    sd_ff = sd(fragf)),
                by = site]


#W################ site!#############################
### IF you add years, then you need to change X and M by changing the number added. 
er_p <- NULL
sd_p <- NULL
year <- NULL
site <- NULL
h<-1
z<-1
x<-1
j<-1
i<- 1

while (z < 45){
  wvb <- hab_mn[i,2]
  wvf <- hab_mn[i,3]
  wsb <- hab_mn[i,4]
  wsf <- hab_mn[i,5]
  wfb <- hab_mn[i,6]
  wff <- hab_mn[i,7]
  sd_vb <- hab_sd[i,2]
  sd_vf <- hab_sd[i,3]
  sd_sb <- hab_sd[i,4]
  sd_sf <- hab_sd[i,5]
  sd_fb <- hab_sd[i,6]
  sd_ff <- hab_sd[i,7]
  sit <- hab_sd[i,1]
  m <-x+36
  cor_hab <- cor(hab[c(x:m),3:8])
  
  #condition assessment
  bc <- (((wvb+wsb)/2+wfb)/2)
  a = ((wvf+wsf)/2+wff+bc)/3
  
  # Variance
  ## Make an array of relative contribution of each attribute 
  #condition score to the total
  vb <- hab_wgt[,1]
  vf <- hab_wgt[,2]
  sb <- hab_wgt[,3]
  sf <- hab_wgt[,4]
  fb <- hab_wgt[,5]
  ff <- hab_wgt[,6]
  
  b = sqrt((vb^2 * sd_vb^2 +
              sb^2 * sd_sb^2 +
              fb^2 * sd_fb^2 +
              vf^2 * sd_vf^2 +
              sf^2 * sd_sf^2 +
              ff^2 * sd_ff^2) +
             ((2 * (vb * sb * sd_vb * sd_sb * cor_hab [1,3])) +
                (2 * (vb * fb * sd_vb * sd_fb * cor_hab [1,5])) +
                (2 * (vb * vf * sd_vb * sd_vf * cor_hab [1,2])) +
                (2 * (vb * sf * sd_vb * sd_sf * cor_hab [1,4])) +
                (2 * (vb * ff * sd_vb * sd_ff * cor_hab [1,6])) +
                (2 * (sb * fb * sd_sb * sd_fb * cor_hab [3,5])) +
                (2 * (sb * vf * sd_sb * sd_vf * cor_hab [3,2])) +
                (2 * (sb * sf * sd_sb * sd_sf * cor_hab [3,4])) +
                (2 * (sb * ff * sd_sb * sd_ff * cor_hab [3,6])) +
                (2 * (fb * vf * sd_fb * sd_vf * cor_hab [5,2])) +
                (2 * (fb * sf * sd_fb * sd_sf * cor_hab [5,4])) +
                (2 * (fb * ff * sd_fb * sd_ff * cor_hab [5,6])) +
                (2 * (vf * sf * sd_vf * sd_sf * cor_hab [2,4])) +
                (2 * (vf * ff * sd_vf * sd_ff * cor_hab [2,6])) +
                (2 * (sf * ff * sd_sf * sd_ff * cor_hab [4,6]))))
  er_p <- rbind(er_p,a)
  sd_p <- rbind(sd_p,b)
  site <- rbind(site,sit)
  i <-i+1  
  z <-z+1
  x <- x+37
}

hab_assets <- (cbind(site,er_p,sd_p))
colnames(hab_assets) <- c("Site", "er_p", "sd_p")
hab_assets <- data.table(hab_assets)
hab_assets <- data.table(hab_assets)
hab_sample <- hab_assets [c(42, 31, 25, 2),]
hab_sample$met <- "Port"
setcolorder(hab_sample, c("site", "met", "er_p", "sd_p"))

write.csv(hab_assets, file = ("Current Data/Final_hab_port_data/hab_sites21.csv"))


# Section 7 - bootstrapping across scale ----------------------------------

reach <- list(44, 40, 35, 30, 25, 20, 15, 10, 5, 4, 3, 2, 1)

####for total river use this########


#for (g in reach){

g=44
hab_yr <- read.csv(sprintf("Current Data/multi_sites/output/final/%d_hab_met.csv",g))
hab <- read.csv(sprintf("Current Data/multi_sites/output/final/%d_hab_met.csv",g))
hab_wgt <- read.csv(sprintf("Current Data/multi_sites/output/final/%d_rel_area.csv",g))
hab_wgt <- hab_wgt[order(hab_wgt$bf.site),]
hab <- hab[order(hab$site),]
a <- nrow((hab_wgt))
site <- c(1:a)
hab_wgt <- hab_wgt[,-c(1:3)]
hab_wgt <- cbind(site,hab_wgt)
hab <- hab[,-1]
indx <- ((((hab$vegb + hab$simpb)/2)+hab$fragb)/2 + ((hab$vegf+hab$simpf)/2)+hab$fragf)/3
fci <- as.data.frame(cbind(hab_yr$year,hab$site, indx))
colnames(fci) <- c("years","site","fci")

###################permutate select sites################

pscale <- NULL
t=1
while (t<45){
  Port_port <- NULL
  xx <- 1
  while (xx<501){
    i=1
    l=1
    subby <- NULL
    samp <- as.data.frame(randperm(1:44, t))
    tot_row <- nrow(samp)
    
    while (l < tot_row+1){
      z = samp[l,]
      q <- subset(fci, site == z,select=c(years,site, fci))
      subby <- rbind(subby, q)
      l<- l+1
    }
    
    #W################ site!#############################
    # Sd's for each year
    habdt <- setDT(subby)
    # calculate the arithmetic returns
    hab_mn <- habdt[, .(er = mean(fci)), 
                    by = site]
    # calculate the sd
    hab_sd <- habdt[, .(sd_fci = sd(fci)),
                    by = site]
    
    # calculate the cov
    dat.wide <- reshape(subby, direction = 'wide',idvar = 'years',
                        timevar = 'site')
    
    a <- ncol(dat.wide) 
    cov_hab <- cov(dat.wide[,2:a])
    hab_wgt <- 1/tot_row
    
    
    #########get er-p and sd-p ##############
    er_p <- NULL
    sd_p <- NULL
    year <- NULL
    site <- NULL
    h<-1
    z<-1
    x<-1
    j<-1
    i<- 1
    y <- nrow(hab)+1
    
    er_p <- sum((hab_mn$er * hab_wgt))
    
    x <- tot_row
    y <- x+1
    i<-1
    j<-1
    c<- 0
    d<-0
    b<-0
    
    
    
    for (i in x){
      j <- i+1
      a = sum((hab_sd$sd_fci[i]^2 * hab_wgt^2))
      d<-d+a
      while (j < x+1){
        b = 2*(hab_wgt*hab_wgt*hab_sd$sd_fci[i]*
                 hab_sd$sd_fci[j]* cov_hab[i,j])
        c = b+c
        j <- j+1
      }
    }
    
    sd_p <- sqrt(d+c)
    
    tot_var <- var(subby$fci)
    tot_sd  <- sd(subby$fci)
    max_cov <- max(cov_hab)
    min_cov <- min(cov_hab)
    max_wgt <- max(hab_wgt)
    min_wgt <- min(hab_wgt)
    
    stuff <- (cbind(x,er_p,sd_p, tot_var, tot_sd, max_cov, min_cov, max_wgt, min_wgt))
    Port_port <- rbind(Port_port, stuff)
    xx=xx+1
  }
  Port_port <- as.data.frame(Port_port)
  mean_er_p <- mean(Port_port$er_p)    
  mean_sd_p  <- mean(Port_port$sd_p)    
  mean_fci_sd <- sqrt(sum(Port_port$tot_var)/500)
  std_fci_err <- mean_sd/sqrt(t)
  max_er_p <- max(Port_port$er_p)
  min_er_p <- min(Port_port$er_p)
  max_sd_p  <- max(Port_port$sd_p)
  min_sd_p  <- min(Port_port$sd_p)
  max_var <- max(Port_port$tot_var)
  min_var <- min(Port_port$tot_var)
  max_sd  <- min(Port_port$tot_sd)
  min_sd  <- min(Port_port$tot_sd)
  mx_maxcov  <- max(Port_port$max_cov)
  mn_maxcov <- min(Port_port$max_cov)
  mx_mincov  <- max(Port_port$min_cov)
  mn_mincov <- min(Port_port$min_cov)
  max_wgt <- max(Port_port$max_wgt)
  
  that <- (cbind(x, mean_er_p, mean_sd_p, mean_fci_sd, std_fci_err, max_er_p, min_er_p, max_sd_p, min_sd_p, max_var, min_var, 
                 max_sd, min_sd, mx_maxcov, mn_maxcov, mx_mincov, mn_mincov, max_wgt))
  pscale <- rbind(pscale, that )
  t <- t+1
}

write.csv(pscale, file = ("D:/Dropbox/publication/11th - portfolio/site_port_scale.csv"))

########################################################################
#Now spatial weighted boots  
######################################################################

g=44
hab_yr <- read.csv(sprintf("Current Data/multi_sites/output/final/%d_hab_met.csv",g))
hab <- read.csv(sprintf("Current Data/multi_sites/output/final/%d_hab_met.csv",g))
hab_wgt <- read.csv(sprintf("Current Data/multi_sites/output/final/%d_rel_area.csv",g))
hab_wgt <- hab_wgt[order(hab_wgt$bf.site),]
hab <- hab[order(hab$site),]
a <- nrow((hab_wgt))
site <- c(1:a)
hab_wgt <- hab_wgt[,-c(1:2)]
hab_wgt <- cbind(site,hab_wgt)
hab <- hab[,-1]
indx <- ((((hab$vegb + hab$simpb)/2)+hab$fragb)/2 + ((hab$vegf+hab$simpf)/2)+hab$fragf)/3
fci <- as.data.frame(cbind(hab_yr$year,hab$site, indx))
colnames(fci) <- c("years","site","fci")

###################permutate select sites################

wgtscale <- NULL
t=2
while (t<45){
  Port_port <- NULL
  xx <- 1
  while (xx<501){
    i=1
    l=1
    subby <- NULL
    wghty <- NULL
    samp <- as.data.frame(randperm(1:44, t))
    tot_row <- nrow(samp)
    
    while (l < tot_row+1){
      z = samp[l,]
      q <- subset(fci, site == z,select=c(years,site, fci))
      w <- subset(hab_wgt, site == z, select=c(site, Total_Area))
      subby <- rbind(subby, q)
      wghty <- rbind(wghty, w)
      l<- l+1
    }
    tot_area <- sum(wghty$Total_Area)
    wghty$rel_area <- wghty$Total_Area/tot_area
    
    # Sd's for each year
    habdt <- setDT(subby)
    # calculate the arithmetic returns
    hab_mn <- habdt[, .(er = mean(fci)), 
                    by = site]
    # calculate the sd
    hab_sd <- habdt[, .(sd_fci = sd(fci)),
                    by = site]
    
    # calculate the cov
    dat.wide <- reshape(subby, direction = 'wide',idvar = 'years',
                        timevar = 'site')
    
    a <- ncol(dat.wide) 
    cov_hab <- cov(dat.wide[,2:a])
    
    
    
    #########get er-p and sd-p ##############
    er_p <- NULL
    sd_p <- NULL
    year <- NULL
    site <- NULL
    h<-1
    z<-1
    x<-1
    j<-1
    i<- 1
    
    er_p <- sum((hab_mn$er * wghty[,3]))
    
    x <- tot_row
    y <- x+1
    i<-1
    j<-1
    c<- 0
    d<-0
    b<-0
    
    
    
    for (i in x){
      j <- i+1
      a = sum((hab_sd$sd_fci[i]^2 * wghty[i,3]^2))
      d<-d+a
      while (j < x+1){
        #  j <- ifelse(i==j,(j=j+1), j)
        b = 2*(wghty[i,3]*wghty[j,3]*hab_sd$sd_fci[i]*
                 hab_sd$sd_fci[j]* cov_hab[i,j])
        c = b+c
        j <- j+1
      }
    }
    
    sd_p <- sqrt(d+c)
    
    tot_var <- var(subby$fci)
    tot_sd  <- sd(subby$fci)
    max_cov <- max(cov_hab)
    min_cov <- min(cov_hab)
    max_wgt <- max(wghty[,3])
    min_wgt <- min(wghty[,3])
    
    stuff <- (cbind(x,er_p,sd_p, tot_var, tot_sd, max_cov, min_cov, max_wgt, min_wgt))
    Port_port <- rbind(Port_port, stuff)
    
    xx=xx+1
  }
  Port_port <- as.data.frame(Port_port)
  mean_er_p <- mean(Port_port$er_p)    
  mean_sd_p  <- mean(Port_port$sd_p)    
  mean_fci_sd <- sqrt(sum(Port_port$tot_var)/500)
  std_fci_err <- mean_fci_sd/sqrt(t)
  max_er_p <- max(Port_port$er_p)
  min_er_p <- min(Port_port$er_p)
  max_sd_p  <- max(Port_port$sd_p)
  min_sd_p  <- min(Port_port$sd_p)
  max_var <- max(Port_port$tot_var)
  min_var <- min(Port_port$tot_var)
  max_sd  <- min(Port_port$tot_sd)
  min_sd  <- min(Port_port$tot_sd)
  mx_maxcov  <- max(Port_port$max_cov)
  mn_maxcov <- min(Port_port$max_cov)
  mx_mincov  <- max(Port_port$min_cov)
  mn_mincov <- min(Port_port$min_cov)
  max_wgt <- max(Port_port$max_wgt)
  
  that <- (cbind(x, mean_er_p, mean_sd_p, mean_fci_sd, std_fci_err, max_er_p, min_er_p, max_sd_p, min_sd_p, max_var, min_var, 
                 max_sd, min_sd, mx_maxcov, mn_maxcov, mx_mincov, mn_mincov, max_wgt))
  wgtscale <- rbind(wgtscale, that )
  t <- t+1
}

write.csv(wgtscale, file = ("D:/Dropbox/publication/11th - portfolio/site_port__wgt_scale.csv"))


# Section 8 Cumulative Volatility  ----------------------------------------
#Above, we looked at the change in portfolio volatility as we increased sample grain; here we increase 
#sample size to see the effect on portfolio volatility 


############## frequency of cover by site and by buffer over time ############
reach <- list(40, 35, 30, 25, 20, 15, 10, 5, 4, 3, 2, 1)
for (i in reach){
  buf <- readOGR(sprintf("Current Data/multi_sites/2021_multi/%d_buf_utm12.shp",i))
  fldpln <- readOGR(sprintf("Current Data/multi_sites/2021_multi/%d_fldpln_utm12.shp",i))
  # buf <- readOGR("Current Data/multi_sites/2021_multi/zone_buf_utm12.shp")
  # fldpln <- readOGR("Current Data/multi_sites/2021_multi/zone_fld_utm12.shp")
  # mrg <- readOGR("Current Data/multi_sites/2021_multi/zone_mrg_utm12.shp")
  
  
  ## Set up df
  dfbuf <- as.data.frame(buf)
  df_fp <- as.data.frame(fldpln)
  df_mrg <- as.data.frame(mrg)
  
  ###Loop through years With buffer data
  for(yr in 1984:2020){
    file <- sprintf("RS Image/The Final Maps/%d_class_final.img", yr)
    r <- raster(file)  
    flood = NULL
    x=1
    rch <- i+1
    while(x<rch){
      v <- raster::extract(r, buf[buf$confluvid == x,])
      flood <- rbind(flood,v)
      x<-x+1
    }
    v.counts <-(lapply(flood,table))
    v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
    p.df <- lapply(v.pct, data.frame)
    c.df <- lapply(v.counts , data.frame)
    p <- NULL
    c <- NULL
    for(j in 1:length(p.df)){
      # row-bind the running df with the table made into a df, and 
      #also prepend column "reach" with current iteration
      p <- rbind(p, data.frame(j, p.df[[j]]))
      c <- rbind(c, data.frame(j, c.df[[j]]))
    }
    colnames(p) <- c("site", "class", "pct")
    colnames(c) <- c("site", "class", "cnt")
    p <- reshape(p, idvar = "site", timevar = "class", direction = "wide")
    c <- reshape(c, idvar = "site", timevar = "class", direction = "wide")
    p[is.na(p)] <- 0 
    c[is.na(c)] <- 0
    write.csv(p, file = sprintf("Current Data/multi_sites/output/%d/%d_buf_pct.csv",i, yr))
    write.csv(c, file = sprintf("Current Data/multi_sites/output/%d/%d_buf_cnt.csv",i, yr))
    print (yr)
  }
  
  ###Loop through years With riparian data
  for(yr in 1984:2020){
    file <- sprintf("RS Image/The Final Maps/%d_class_final.img", yr)
    r <- raster(file)  
    flood = NULL
    x=1
    rch <- i+1
    while(x<rch){
      v <- raster::extract(r, fldpln[fldpln$sites == x,])
      flood <- rbind(flood,v)
      x<-x+1
    }
    v.counts <-(lapply(flood,table))
    v.pct <- lapply(v.counts, FUN=function(x){ x / sum(x) } )
    p.df <- lapply(v.pct, data.frame)
    c.df <- lapply(v.counts , data.frame)
    p <- NULL
    c <- NULL
    for(j in 1:length(p.df)){
      # row-bind the running df with the table made into a df, and 
      #also prepend column "reach" with current iteration
      p <- rbind(p, data.frame(j, p.df[[j]]))
      c <- rbind(c, data.frame(j, c.df[[j]]))
    }
    colnames(p) <- c("site", "class", "pct")
    colnames(c) <- c("site", "class", "cnt")
    p <- reshape(p, idvar = "site", timevar = "class", direction = "wide")
    c <- reshape(c, idvar = "site", timevar = "class", direction = "wide")
    p[is.na(p)] <- 0 
    c[is.na(c)] <- 0
    write.csv(p, file = sprintf("Current Data/multi_sites/output/%d/%d_fldpln_pct.csv",i, yr))
    write.csv(c, file = sprintf("Current Data/multi_sites/output/%d/%d_fldpln_cnt.csv", i, yr))
    print (yr)
  }
  print(i)
}

#####################Frag Numbers######################
## Reset WD
#prepping site DF
reach <- list(40, 35, 30, 25, 20, 15, 10, 5, 4, 3, 2, 1)

for (i in reach){
  buf <- readOGR(sprintf("Current Data/multi_sites/2021_multi/%d_buf_utm12.shp",i))
  fldpln <- readOGR(sprintf("Current Data/multi_sites/2021_multi/%d_fldpln_utm12.shp",i))
  
  
  ## Set up df
  dfbuf <- as.data.frame(buf)
  df_fp <- as.data.frame(fldpln)
  
  buffer_frag <- NULL
  fld_frag <- NULL
  
  
  for(yr in 1984:2020){
    file<-sprintf("Current Data/Frag/frag maps/%d_frag.img", yr)
    frag <- raster(file) 
    
    #Buffer Perturbation
    flood = NULL
    x=1
    rch <- i+1
    while(x<rch){
      v <- raster::extract(frag, buf[buf$confluvid == x,], fun=mean)
      flood <- rbind(flood,v)
      x<-x+1
    }
    # buffer_frag <- flood
    buffer_frag <- cbind(buffer_frag, flood)
    flood = NULL
    x=1
    rch <- i+1
    while(x<rch){
      v <- raster::extract(frag, fldpln[fldpln$sites == x,], fun=mean)
      flood <- rbind(flood,v)
      x<-x+1
    }  
    # fld_frag <- flood
    fld_frag <- cbind(fld_frag, flood)
    print(yr)
  }
  
  
  colnames(fld_frag) <- c(1984:2020)
  colnames(buffer_frag) <- c(1984:2020)
  write.csv(fld_frag, sprintf("Current Data/multi_sites/output/%d_fldpln_frag.csv",i))
  write.csv(buffer_frag, sprintf("Current Data/multi_sites/output/%d_buf_frag.csv",i))
  print(i)
}

##########################################
####anthro Metric ########################
####By Site       ########################
##########################################
#######################Run all years ###############################################
########### FCI For all sites, zones and tot ########################################
#anthro <- c(1,1,1,1,1,1,1,0.5,0,1,0.3)
checkn <- matrix(c(1,1,1,1,1,1,1,0.25,0,1,0.5), nrow = 1, ncol = 11)
classes <- c("pct1","pct2","pct4","pct5","pct6","pct7","pct8","pct10","pct11","pct13","pct15")
names(checkn) <- classes
checkn <- checkn[,order (names(checkn))]

##############By year and by reach density##############################
reach <- list(40, 35, 30, 25, 20, 15, 10, 5, 4, 3, 2, 1)

for (i in reach){
  
  buf <- readOGR(sprintf("Current Data/multi_sites/2021_multi/%d_buf_utm12.shp",i))
  fldpln <- readOGR(sprintf("Current Data/multi_sites/2021_multi/%d_fldpln_utm12.shp",i))
  
  ## Set up df
  anthro_met_buf <- as.data.frame(buf)
  anthro_met_fp <- as.data.frame(fldpln)
  anthro_met_fp <- anthro_met_fp [,-c(1:10)]
  anthro_met_buf <- anthro_met_buf[,-c(1:4)]
  anthro_met_buf$site <- c(1:i)
  anthro_met_fp$site <- c(1:i)
  
  ### Floodplain ###
  for(yr in 1984:2020){
    file <- sprintf("Current Data/multi_sites/output/%d/%d__fldpln_pct.csv", i, yr)
    pct <- read.csv(file, header = TRUE)
    pct<-pct[,-1]
    pct <- pct %>% arrange(site)
    x <- pct[,order (names(pct))]
    x = matrix(as.numeric(unlist(x)),nrow=nrow(x))
    pert_fp <- x[,1:11]%*%checkn
    anthro_met_fp <- cbind(anthro_met_fp, pert_fp)
  }
  anthro_met_fp=as.data.frame(anthro_met_fp)
  names(anthro_met_fp) <- c("site","1984","1985","1986","1987","1988","1989",
                            "1990","1991","1992","1993","1994","1995","1996","1997","1998","1999",
                            "2000","2001","2002","2003","2004","2005","2006","2007","2008","2009",
                            "2010","2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018","2019","2020")
  
  write.csv(anthro_met_fp, file = sprintf("Current Data/multi_sites/output/zone/%d_anthro_met_fp.csv",i))
  
  ### Buffer ###
  for(yr in 1984:2020){
    file <- sprintf("Current Data/multi_sites/output/%d/%d__buf_pct.csv", i, yr)
    pct <- read.csv(file, header = TRUE)
    pct<-pct[,-1]
    pct <- pct %>% arrange(site)
    x <- pct[,order (names(pct))]
    x= matrix(as.numeric(unlist(x)),nrow=nrow(x))
    pert_buf <- x[,1:11]%*%checkn
    anthro_met_buf <- cbind(anthro_met_buf, pert_buf)
  }
  anthro_met_buf=as.data.frame(anthro_met_buf)
  names(anthro_met_buf) <- c("site","1984","1985","1986","1987","1988","1989",
                             "1990","1991","1992","1993","1994","1995","1996","1997","1998","1999",
                             "2000","2001","2002","2003","2004","2005","2006","2007","2008","2009",
                             "2010","2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018","2019","2020")
  
  write.csv(anthro_met_buf, file = sprintf("Current Data/multi_sites/output/%d_anthro_met_buf.csv",i))
  print(i)
  
  
  ############## frequency of cover by site and by buffer over time ############
  div_d_b <- as.data.frame(buf)
  div_d_f <- as.data.frame(fldpln)
  div_d_f <- div_d_f [,-c(1:3)]
  div_d_b <- div_d_b[,-c(1:2)]
  div_d_b$site <- c(1:i)
  div_d_f$site <- c(1:i)
  
  
  ### Load in pixel counts
  nam <- c("site","1984","1985","1986","1987","1988","1989",
           "1990","1991","1992","1993","1994","1995","1996","1997","1998","1999",
           "2000","2001","2002","2003","2004","2005","2006","2007","2008","2009",
           "2010","2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018","2019","2020")
  
  
  ##############  Floodplain  #############################
  
  for(yr in 1984:2020){
    file <- sprintf("Current Data/multi_sites/output/%d/%d_fldpln_cnt.csv",i, yr)
    pct <- read.csv(file, header = TRUE)
    pct <- pct[,order (names(pct))]
    x<- pct[,c(1,4,6,7,8,9,10,11)]
    x= matrix(as.numeric(unlist(x)),nrow=nrow(x))
    D <-diversity(x,index = "simpson")
    div_d_f <- cbind(div_d_f, D) 
    yr <- yr+1
  }
  div_d_f=as.data.frame(div_d_f)
  colnames(div_d_f) <- nam
  
  write.csv(div_d_f, file = sprintf("Current Data/multi_sites/output/%d_div_fldpln_simpson.csv", i))
  
  ### Buffer ###
  
  ##############  Floodplain  #############################
  for(yr in 1984:2020){
    file <- sprintf("Current Data/multi_sites/output/%d/%d_buf_cnt.csv",i, yr)
    pct <- read.csv(file, header = TRUE)
    pct <- pct[,order (names(pct))]
    x<- pct[,c(1,4,6,7,8,9,10,11)]
    x= matrix(as.numeric(unlist(x)),nrow=nrow(x))
    D <-diversity(x,index = "simpson")
    div_d_b <- cbind(div_d_b, D) 
    yr <- yr+1
  }
  div_d_b=as.data.frame(div_d_b)
  colnames(div_d_b) <- nam
  
  write.csv(div_d_b, file = sprintf("Current Data/multi_sites/output/%d_div_buf_simpson.csv",i)) 
  print(i)
}

##########################################
####setting up FCIs ########################
####By Site       ########################
##########################################
reach <- list(40, 35, 30, 25, 20, 15, 10, 5, 4, 3, 2, 1)

clean2 <- function (x){
  
  x <- x[,-1] 
  y = nrow(x)
  x <- as.data.frame(t(x))
  yr <- c(1984:2020)
  x <- cbind(yr,x)
  nam <- c("year",c(1:y))
  colnames(x) <- nam
  melt(x, id=c("year"))}

for (i in reach){
  vegb <- read.csv("Current Data/multi_sites/output/zone/44_anthro_met_buf.csv")
  vegf <- read.csv("Current Data/multi_sites/output/zone/44_anthro_met_fp.csv")
  simpb <- read.csv("Current Data/multi_sites/output/zone/44_div_buf_simpson.csv")
  simpf <- read.csv("Current Data/multi_sites/output/zone/44_div_fldpln_simpson.csv")
  fragb <- read.csv("Current Data/multi_sites/output/zone/44_buf_frag.csv")
  fragf <- read.csv("Current Data/multi_sites/output/zone/44_fldpln_frag.csv")
  colnames(fragb) <- c("cut","site",c(1984:2020)) 
  colnames(fragf) <- c("cut","site", c(1984:2020))
  
  
  mvegb <- clean(vegb)
  colnames(mvegb) <- c("year","site","vegb")
  #print(head(mvegb, 5))
  
  mvegf <- clean(vegf)
  colnames(mvegf) <- c("year","site","vegf")
  #print(head(mvegf, 5))
  
  msimpb <- clean(simpb)
  colnames(msimpb) <- c("year","site","simpb")
  #print(head(msimpb, 5))
  
  msimpf <- clean(simpf)
  colnames(msimpf) <- c("year","site","simpf")
  #print(head(msimpf, 5))
  
  mfragb <- clean2(fragb)
  colnames(mfragb) <- c("year","site","fragb")
  #print(head(mfragb, 5))
  
  mfragf <- clean2(fragf)
  colnames(mfragf) <- c("year","site","fragf")
  #print(head(mfragf, 5))
  
  tot <- NULL
  tot <- cbind(mvegb,mvegf[,3])
  tot <- cbind(tot,msimpb[,3])
  tot <- cbind(tot,msimpf[,3])
  tot <- cbind(tot,mfragb[,3])
  tot <- cbind(tot,mfragf[,3])
  colnames(tot)<- c("year","site","vegb","vegf","simpb","simpf","fragb","fragf")
  print(tail(tot, 5))
  print(i)
  
  write.csv(tot, file = (sprintf("Current Data/multi_sites/output/final/%d_2_hab_met.csv",i)))
  
}
########################################
####Do the work for all of it ##########
##########################################
####for total river use this########

##########set assets weight#########################
hab <- read.csv("Current Data/1Total River_Attributes/Metrics/Reaches/hab_met.csv")
hab<-hab[,-1]
hab<-as.data.frame(hab)
#
hab_wgt <- (hab[1,-c(1:2)])
hab_wgt <- rbind(hab_wgt,c(.08333,.16667,.08333,.16667,.16667,.33333))
hab_wgt <- (hab_wgt[-1,])

#################### Get the SD for all reach types #######################
############ ############################
reach <- list(45, 40, 35, 30, 25, 20, 15, 10, 5, 4, 3, 2, 1)

### For cumulative risk use this####
for (g in reach){
  hab <- read.csv(sprintf("Current Data/multi_sites/output/final/%d_hab_met.csv",g))
  hab<-hab[,-1]
  
  #W################ site!#############################
  # Sd's for each site
  habdt <- setDT(hab)
  
  # calculate the arithmetic returns
  hab_mn <- habdt[, .(vb = mean(vegb), 
                      vf = mean(vegf), 
                      sb = mean(simpb), 
                      sf = mean(simpf), 
                      fb = mean(fragb), 
                      ff = mean(fragf)),
                  by = site]
  
  # calculate the arithmetic returns
  hab_sd <- habdt[, .(sd_vb = sd(vegb), 
                      sd_vf = sd(vegf), 
                      sd_sb = sd(simpb), 
                      sd_sf = sd(simpf), 
                      sd_fb = sd(fragb), 
                      sd_ff = sd(fragf)),
                  by = site]
  
  #########get er-p and sd-p ##############
  er_p <- NULL
  sd_p <- NULL
  year <- NULL
  site <- NULL
  h<-1
  z<-1
  x<-1
  j<-1
  i<- 1
  y <- nrow(hab_mn)+1
  
  while (z < y){
    wvb <- hab_mn[i,2]
    wvf <- hab_mn[i,3]
    wsb <- hab_mn[i,4]
    wsf <- hab_mn[i,5]
    wfb <- hab_mn[i,6]
    wff <- hab_mn[i,7]
    sd_vb <- hab_sd[i,2]
    sd_sb <- hab_sd[i,3]
    sd_fb <- hab_sd[i,4]
    sd_vf <- hab_sd[i,5]
    sd_sf <- hab_sd[i,6]
    sd_ff <- hab_sd[i,7]
    sit <- hab_sd[i,1]
    m <-x+36
    cor_hab <- cor(hab[c(x:m),3:8])
    
    #condition assessment
    bc <- (((wvb+wsb)/2+wfb)/2)
    a = ((wvf+wsf)/2+wff+bc)/3
    
    # Varaiance
    ## Make an array of relative contribution of each attribute 
    #condition score to the total
    vb <- hab_wgt[,1]
    vf <- hab_wgt[,2]
    sb <- hab_wgt[,3]
    sf <- hab_wgt[,4]
    fb <- hab_wgt[,5]
    ff <- hab_wgt[,6]
    
    b = sqrt(vb^2 * sd_vb^2 +
               sb^2 * sd_sb^2 +
               fb^2 * sd_fb^2 +
               vf^2 * sd_vf^2 +
               sf^2 * sd_sf^2 +
               ff^2 * sd_ff^2 +
               2 * vb * sb * sd_vb * sd_sb * cor_hab [1,3] +
               2 * vb * fb * sd_vb * sd_fb * cor_hab [1,5] +
               2 * vb * vf * sd_vb * sd_vf * cor_hab [1,2] +
               2 * vb * sf * sd_vb * sd_sf * cor_hab [1,4] +
               2 * vb * ff * sd_vb * sd_ff * cor_hab [1,6] +
               2 * sb * fb * sd_sb * sd_fb * cor_hab [3,5] +
               2 * sb * vf * sd_sb * sd_vf * cor_hab [3,2] +
               2 * sb * sf * sd_sb * sd_sf * cor_hab [3,4] +
               2 * sb * ff * sd_sb * sd_ff * cor_hab [3,6] +
               2 * fb * vf * sd_fb * sd_vf * cor_hab [5,2] +
               2 * fb * sf * sd_fb * sd_sf * cor_hab [5,4] +
               2 * fb * ff * sd_fb * sd_ff * cor_hab [5,6] +
               2 * vf * sf * sd_vf * sd_sf * cor_hab [2,4] +
               2 * vf * ff * sd_vf * sd_ff * cor_hab [2,6] +
               2 * sf * ff * sd_sf * sd_ff * cor_hab [4,6])
    er_p <- rbind(er_p,a)
    sd_p <- rbind(sd_p,b)
    site <- rbind(site,sit)
    i <-i+1  
    z <-z+1
    x <- x+37
  }
  
  
  tot_port <- (cbind(site,er_p,sd_p))
  colnames(tot_port) <- c( "Site", "er_p", "sd_p")
  tot_port <- data.table(tot_port)
  write.csv(tot_port, sprintf("Current Data/multi_sites/output/Final Port Output/%d_hab_sd_er.csv", g))
}

##### For whole river use this
write.csv(tot_port, file = ("Current Data/multi_sites/output/Final Port Output/44_hab_sd_er.csv"))

######For zones by decade use this #######################
############ ############################

hab <- read.csv("Current Data/multi_sites/output/final/zone_hab_met.csv")
hab<-hab[,-1]
hab_yr <- hab[order(hab$year),]
hab_80 <- hab_yr[(hab_yr$year<1990),]
hab_90 <- hab_yr[(hab_yr$year>1989), ]
hab_90 <- hab_90[(hab_90$year<2000), ]
hab_00 <- hab_yr[(hab_yr$year>1999),]
hab_00 <- hab_00[(hab_00$year<2010),]
hab_10 <- hab_yr[(hab_yr$year>2009),]

#W################ site!#############################
reach <- list(hab_80, hab_90, hab_00, hab_10)
lst=1

for (g in reach){  
  hab <- g
  
  habdt <- setDT(hab)
  
  # calculate the arithmetic returns
  hab_mn <- habdt[, .(vb = mean(vegb), 
                      vf = mean(vegf), 
                      sb = mean(simpb), 
                      sf = mean(simpf), 
                      fb = mean(fragb), 
                      ff = mean(fragf)),
                  by = site]
  
  # calculate the arithmetic returns
  hab_sd <- habdt[, .(sd_vb = sd(vegb), 
                      sd_vf = sd(vegf), 
                      sd_sb = sd(simpb), 
                      sd_sf = sd(simpf), 
                      sd_fb = sd(fragb), 
                      sd_ff = sd(fragf)),
                  by = site]
  
  #########get er-p and sd-p ##############
  er_p <- NULL
  sd_p <- NULL
  year <- NULL
  site <- NULL
  h<-1
  z<-1
  x<-1
  j<-1
  i<- 1
  y <- nrow(hab_mn)+1
  
  while (z < y){
    wvb <- hab_mn[i,2]
    wvf <- hab_mn[i,3]
    wsb <- hab_mn[i,4]
    wsf <- hab_mn[i,5]
    wfb <- hab_mn[i,6]
    wff <- hab_mn[i,7]
    sd_vb <- hab_sd[i,2]
    sd_sb <- hab_sd[i,3]
    sd_fb <- hab_sd[i,4]
    sd_vf <- hab_sd[i,5]
    sd_sf <- hab_sd[i,6]
    sd_ff <- hab_sd[i,7]
    sit <- hab_sd[i,1]
    cor_hab <- cor(hab[,3:8])
    
    #condition assessment
    bc <- (((wvb+wsb)/2+wfb)/2)
    a = ((wvf+wsf)/2+wff+bc)/3
    
    # Varaiance
    ## Make an array of relative contribution of each attribute 
    #condition score to the total
    vb <- hab_wgt[,1]
    vf <- hab_wgt[,2]
    sb <- hab_wgt[,3]
    sf <- hab_wgt[,4]
    fb <- hab_wgt[,5]
    ff <- hab_wgt[,6]
    
    b = sqrt(vb^2 * sd_vb^2 +
               sb^2 * sd_sb^2 +
               fb^2 * sd_fb^2 +
               vf^2 * sd_vf^2 +
               sf^2 * sd_sf^2 +
               ff^2 * sd_ff^2 +
               ((2 * (vb * sb * sd_vb * sd_sb * cor_hab [1,3])) +
                  (2 * (vb * fb * sd_vb * sd_fb * cor_hab [1,5])) +
                  (2 * (vb * vf * sd_vb * sd_vf * cor_hab [1,2])) +
                  (2 * (vb * sf * sd_vb * sd_sf * cor_hab [1,4])) +
                  (2 * (vb * ff * sd_vb * sd_ff * cor_hab [1,6])) +
                  (2 * (sb * fb * sd_sb * sd_fb * cor_hab [3,5])) +
                  (2 * (sb * vf * sd_sb * sd_vf * cor_hab [3,2])) +
                  (2 * (sb * sf * sd_sb * sd_sf * cor_hab [3,4])) +
                  (2 * (sb * ff * sd_sb * sd_ff * cor_hab [3,6])) +
                  (2 * (fb * vf * sd_fb * sd_vf * cor_hab [5,2])) +
                  (2 * (fb * sf * sd_fb * sd_sf * cor_hab [5,4])) +
                  (2 * (fb * ff * sd_fb * sd_ff * cor_hab [5,6])) +
                  (2 * (vf * sf * sd_vf * sd_sf * cor_hab [2,4])) +
                  (2 * (vf * ff * sd_vf * sd_ff * cor_hab [2,6])) +
                  (2 * (sf * ff * sd_sf * sd_ff * cor_hab [4,6]))))
    er_p <- rbind(er_p,a)
    sd_p <- rbind(sd_p,b)
    site <- rbind(site, sit)
    i <-i+1  
    z <-z+1
    x <- x+36
  }
  
  
  tot_port <- (cbind(site,er_p,sd_p))
  colnames(tot_port) <- c( "Site", "er_p", "sd_p")
  tot_port <- data.table(tot_port)
  
  bub <- list("hab_80", "hab_90", "hab_00", "hab_10")
  write.csv(tot_port, sprintf("Current Data/multi_sites/output/Final Port Output/%s_hab_sd_er.csv", bub[[lst]]))
  lst=lst+1
}



##############################################################################
############################### Portfolio of Portfolios...#####################
#############################################################################

############as above but spatially weighted ############################
reach <- list(45,40, 35, 30, 25, 20, 15, 10, 5, 4, 3, 2, 1)

####Relative area########

for (g in reach){
  #prepping site DF
  
  buf <- readOGR(sprintf("Current Data/multi_sites/2021_multi/%d_buf_utm12.shp",g))
  fldpln <- readOGR(sprintf("Current Data/multi_sites/2021_multi/%d_fldpln_utm12.shp",g))
  
  ## Set up df
  bf <- as.data.frame(buf)
  fp <- as.data.frame(fldpln)
  fp <- fp %>% arrange(as.numeric(as.character(Buffer_Nam)))
  bf <- bf %>% arrange(as.numeric(as.character(Buffer_Nam)))
  fp <- fp [,-1]
  bf <- bf[,-1]
  colnames(bf) <- c("site", "area")
  colnames(fp) <- c("site", "area")
  tots <- as.data.frame(bf$site)
  
  Total_Area <- bf$area + fp$area
  tots <- cbind(tots,Total_Area)
  Rel_Area <- Total_Area/sum(Total_Area)
  tots <- cbind(tots,Rel_Area)
  write.csv(tots, file = (sprintf("Current Data/multi_sites/output/final/%d_rel_area.csv",g)))
}

##### Relative area of main reaches (44) #########
## Set up df
buf <- readOGR("GIS Background/2021/buf_utm12.shp")
fldpln <- readOGR("GIS Background/2021/flp_UTM12.shp")
## Set up df
bf <- as.data.frame(buf)
fp <- as.data.frame(fldpln)
fp <- fp %>% arrange(as.numeric(as.character(sites)))
bf <- bf %>% arrange(as.numeric(as.character(confluvid)))
fp <- fp [,-c(1:8)]
bf <- bf[,-c(1:2)]
colnames(bf) <- c("area","site")
colnames(fp) <- c("site", "area")
tots <- as.data.frame(bf$site)

Total_Area <- bf$area + fp$area
tots <- cbind(tots,Total_Area)
Rel_Area <- Total_Area/sum(Total_Area)
tots <- cbind(tots,Rel_Area)
write.csv(tots, "Current Data/multi_sites/output/final/44_rel_area.csv")


#################### Get the portfolio for all reach types #######################
################### based on spatially weighted FCI only #########################



reach <- list(44, 40, 35, 30, 25, 20, 15, 10, 5, 4, 3, 2, 1)

####for total river use this########

Port_port <- NULL

for (g in reach){
  hab_yr <- read.csv(sprintf("Current Data/multi_sites/output/final/%d_hab_met.csv",g))
  hab <- read.csv(sprintf("Current Data/multi_sites/output/final/%d_hab_met.csv",g))
  hab_wgt <- read.csv(sprintf("Current Data/multi_sites/output/final/%d_rel_area.csv",g))
  hab_wgt <- hab_wgt[order(hab_wgt$bf.site),]
  hab <- hab[order(hab$site),]
  a <- nrow((hab_wgt))
  site <- c(1:a)
  hab_wgt <- hab_wgt[,-c(1:3)]
  hab_wgt <- cbind(site,hab_wgt)
  hab <- hab[,-1]
  indx <- ((((hab$vegb + hab$simpb)/2)+hab$fragb)/2 + ((hab$vegf+hab$simpf)/2)+hab$fragf)/3
  fci <- as.data.frame(cbind(hab_yr$year,hab$site, indx))
  colnames(fci) <- c("years","site","fci")
  
  #W################ site!#############################
  # Sd's for each year
  habdt <- setDT(fci)
  # calculate the arithmetic returns
  hab_mn <- habdt[, .(er = mean(fci)), 
                  by = site]
  # calculate the sd
  hab_sd <- habdt[, .(sd_fci = sd(fci)),
                  by = site]
  
  # calculate the cor
  dat.wide <- reshape(fci, direction = 'wide',idvar = 'years',
                      timevar = 'site')
  
  a <- ncol(dat.wide) 
  cor_hab <- cor(dat.wide[,2:a])
  
  
  #########get er-p and sd-p ##############
  er_p <- NULL
  sd_p <- NULL
  year <- NULL
  site <- NULL
  h<-1
  z<-1
  x<-1
  j<-1
  i<- 1
  y <- nrow(hab)+1
  
  er_p <- sum((hab_mn$er * hab_wgt[,2]))
  
  x <- nrow((hab_wgt))
  y <- x+1
  i<-1
  j<-1
  c<- 0
  d<-0
  b<-0
  
  
  
  for (i in x){
    j <- i+1
    a = sum((hab_sd$sd_fci[i]^2 * hab_wgt[i,2]^2))
    d<-d+a
    while (j < x+1){
      #  j <- ifelse(i==j,(j=j+1), j)
      b = 2*(hab_wgt[i,2]*hab_wgt[j,2]*hab_sd$sd_fci[i]*
               hab_sd$sd_fci[j]* cor_hab[i,j])
      c = b+c
      j <- j+1
    }
  }
  
  sd_p <- sqrt(d+c)
  
  stuff <- (cbind(x,er_p,sd_p))
  Port_port <- rbind(Port_port, stuff)
  
}

#for whole river
a = sum((hab_sd$sd_fci[i]^2 * hab_wgt[i,2]^2))
b = 2*(hab_wgt[i,2]*hab_sd$sd_fci[i]*
         cor_hab[i,])
sd_p <- sqrt(a+b)
stuff <- (cbind(x,er_p,sd_p))
Port_port <- rbind(Port_port[-13,], stuff)

#then save

colnames(Port_port) <- c("scale", "er_p", "sd_p")
write.csv(Port_port, file = ("Current Data/multi_sites/output/Final Port Output/port_port_hab_sd_er.csv"))


##### For whole river use this
write.csv(hab_assets, file = ("Current Data/multi_sites/output/final/0_hab_sd_er.csv"))




#################### Get the portfolio for all reach types #######################
################### based on spatially weighted metrics leading to FCI############

#################### Get the SD for all reach types #######################
############ ############################
reach <- list(44, 40, 35, 30, 25, 20, 15, 10, 5, 4, 3, 2, 1)
wgt_scale <- NULL

for (g in reach){
  hab <- read.csv(sprintf("Current Data/multi_sites/output/final/%d_hab_met.csv",g))
  hab<-hab[,-1]
  hab<-as.data.frame(hab)
  hab_wgt <- read.csv(sprintf("Current Data/multi_sites/output/final/%d_rel_area.csv",g))
  a <- nrow((hab_wgt))
  site <- c(1:a)
  hab_wgt <- (hab[1,-c(1:2)])
  hab_wgt[1,] <- c(.08333,.16667,.08333,.16667,.16667,.33333)
  
  # Sd's for each year
  habdt <- setDT(hab)
  
  # calculate the arithmetic returns
  hab_mn <- habdt[, .(vb = mean(vegb), 
                      vf = mean(vegf), 
                      sb = mean(simpb), 
                      sf = mean(simpf), 
                      fb = mean(fragb), 
                      ff = mean(fragf)),
                  by = site]
  
  # calculate the arithmetic returns
  hab_sd <- habdt[, .(sd_vb = sd(vegb), 
                      sd_vf = sd(vegf), 
                      sd_sb = sd(simpb), 
                      sd_sf = sd(simpf), 
                      sd_fb = sd(fragb), 
                      sd_ff = sd(fragf)),
                  by = site]
  
  #########get er-p and sd-p ##############
  er_p <- NULL
  var_p <- NULL
  year <- NULL
  site <- NULL
  h<-1
  z<-1
  x<-1
  j<-1
  i<- 1
  y <- nrow(hab_mn)+1
  
  while (z < y){
    wvb <- hab_mn[i,2]
    wvf <- hab_mn[i,3]
    wsb <- hab_mn[i,4]
    wsf <- hab_mn[i,5]
    wfb <- hab_mn[i,6]
    wff <- hab_mn[i,7]
    sd_vb <- hab_sd[i,2]
    sd_vf <- hab_sd[i,3]
    sd_sb <- hab_sd[i,4]
    sd_sf <- hab_sd[i,5]
    sd_fb <- hab_sd[i,6]
    sd_ff <- hab_sd[i,7]
    sit <- hab_sd[i,1]
    m <-x+36
    cor_hab <- cor(hab[c(x:m),3:8])
    
    #condition assessment
    bc <- (((wvb+wsb)/2+wfb)/2)
    a = ((wvf+wsf)/2+wff+bc)/3
    
    # Variance
    ## Make an array of relative contribution of each attribute 
    #condition score to the total
    vb <- hab_wgt[,1]
    vf <- hab_wgt[,2]
    sb <- hab_wgt[,3]
    sf <- hab_wgt[,4]
    fb <- hab_wgt[,5]
    ff <- hab_wgt[,6]
    
    
    b = sqrt((vb^2 * sd_vb^2 +
                sb^2 * sd_sb^2 +
                fb^2 * sd_fb^2 +
                vf^2 * sd_vf^2 +
                sf^2 * sd_sf^2 +
                ff^2 * sd_ff^2 +
                ((2 * (vb * sb * sd_vb * sd_sb * cor_hab [1,3])) +
                   (2 * (vb * fb * sd_vb * sd_fb * cor_hab [1,5])) +
                   (2 * (vb * vf * sd_vb * sd_vf * cor_hab [1,2])) +
                   (2 * (vb * sf * sd_vb * sd_sf * cor_hab [1,4])) +
                   (2 * (vb * ff * sd_vb * sd_ff * cor_hab [1,6])) +
                   (2 * (sb * fb * sd_sb * sd_fb * cor_hab [3,5])) +
                   (2 * (sb * vf * sd_sb * sd_vf * cor_hab [3,2])) +
                   (2 * (sb * sf * sd_sb * sd_sf * cor_hab [3,4])) +
                   (2 * (sb * ff * sd_sb * sd_ff * cor_hab [3,6])) +
                   (2 * (fb * vf * sd_fb * sd_vf * cor_hab [5,2])) +
                   (2 * (fb * sf * sd_fb * sd_sf * cor_hab [5,4])) +
                   (2 * (fb * ff * sd_fb * sd_ff * cor_hab [5,6])) +
                   (2 * (vf * sf * sd_vf * sd_sf * cor_hab [2,4])) +
                   (2 * (vf * ff * sd_vf * sd_ff * cor_hab [2,6])) +
                   (2 * (sf * ff * sd_sf * sd_ff * cor_hab [4,6])))))
    er_p <- rbind(er_p,a)
    var_p <- rbind(var_p,b)
    site <- rbind(site,sit)
    i <-i+1  
    z <-z+1
    x <- x+37
  }
  sd_er <- cbind(site,er_p, var_p)
  colnames(sd_er) <- c( "site", "er_p", "sd_p")
  write.csv(sd_er, sprintf("Current Data/multi_sites/output/final/%d_hab_sd_er.csv",g))
  
}

# Section 9 Final Figures -------------------------------------------------

## Several final figures were made here, but others were cleaned in Illustrator. 

##### Figure 2 PREP - average by land use cover across all years ###########################
avguse <- NULL
avguse <- cbind(avguse,lu[,c(12)])
avgconfor <- avguse
avgdecfor <- avguse
avgimdec <- avguse
avgshrub <- avguse
avgmed <- avguse
avgpstfir <- avguse
avgcobb <- avguse
avgriv <- avguse
avgnat <- avguse
avgurb <- avguse
avgag <- avguse
avglog <- avguse

for(yr in 1984:2020){
  data <- read.csv(sprintf("Current Data/merg_pct/2021_new/%d_merg_pct.csv", yr), header = TRUE)
  data <- data[order(data[,1]),]
  data <- data[,-2]
  data <- data[order(names(data))]
  
  lu <- data
  avgconfor <- cbind(avgconfor,lu[,c(1)])
  avgdecfor <- cbind(avgdecfor,lu[,c(6)])
  avgimdec <- cbind(avgimdec,lu[,c(7)])
  avgshrub <- cbind(avgshrub,lu[,c(8)])
  avgmed <- cbind(avgmed,lu[,c(9)])
  avgpstfir <- cbind(avgpstfir,lu[,c(4)])
  avgcobb <- cbind(avgcobb,lu[,c(10)])
  avgriv <- cbind(avgriv,lu[,c(11)])
  avgnat <- cbind(avgnat,rowSums(lu[,c(1,4,6,7,8,9,10,11)]))
  avgurb <- cbind(avgurb,lu[,c(3)])
  avgag <- cbind(avgag,lu[,c(2)]) 
  avglog <- cbind(avglog,lu[,c(5)])
}
meanconfor <- rowMeans(avgconfor[,-1])
meandecfor <- rowMeans(avgdecfor[,-1])
meanimdec <- rowMeans(avgimdec[,-1])
meanshrub <- rowMeans(avgshrub[,-1])
meanmedo <- rowMeans(avgmed[,-1])
meanpstfr <- rowMeans(avgpstfir[,-1])
meanvob <- rowMeans(avgcobb[,-1])
meanriv <- rowMeans(avgriv[,-1])
meannat <- rowMeans(avgnat[,-1])
#mednat <- apply(avgnat[,-1], 1, median)   
meanurb <- rowMeans(avgurb[,-1])
#medurb <- apply(avgurb[,-1], 1, median)   
meanag <- rowMeans(avgag[,-1])
#medag <- apply(avgag[,-1], 1, median)   
meanlog <- rowMeans(avglog[,-1])
#medlog <- apply(avglog[,-1], 1, median)   

meanuse <- cbind(avguse,meannat, meanurb, meanag, meanlog)
colnames(meanuse) <- c("site", "Natural","Urban", "Agriculture","Logging")

meanuse_all <- cbind(avguse, meanconfor, meandecfor, meanimdec, meanshrub, meanmedo, 
                     meanpstfr,meanvob, meanriv, meanurb,  meanag, meanlog)
colnames(meanuse_all) <- c("site", "Mature Conifer","Deciduous Forest","Immature Deciduous",
                           "Shrub","Meadow", "Post Fire","Cobble","River",
                           "Urban", "Agriculture","Logging")

write.csv(meanuse, file = ("Current Data/1Total River_Attributes/Metrics/Reaches/mean_land_use21.csv"))
write.csv(meanuse_all, file = ("Current Data/1Total River_Attributes/Metrics/Reaches/mean_land_use_all21.csv"))

####For ggplot all landuse Figure 2####

meanuse_all <- read.csv("Current Data/1Total River_Attributes/Metrics/Reaches/mean_land_use_all21.csv")
meanuse_all <- meanuse_all[order(meanuse_all[,1]),]
meanuse_all <- meanuse_all[,-1]
colnames(meanuse_all) <- c("Reach", "Mature Conifer","Mature Decid","Immat Decid",
                           "Shrub","Meadow", "Post Fire","Cobble","River",
                           "Urban", "Agri","Logging")
rownames(meanuse_all) <- c(1:44)
mdata_all <- reshape2::melt(meanuse_all[, c(1:12)], id=c("Reach"))
#mdata_all <- melt(meanuse_all[,c(1:12)]
colnames(mdata_all) <- c("site", "lndcov", "pctcov")

# Stacked + percent for GGPLOT
#for saving only do not run the 'windows(height=6, width=9.75)' command when saving
jpeg('D:/Dropbox/publication/11th - portfolio/Applications Submission/Final Figures/figure 2_300.jpeg', 
     height=6, width=9.75, units=c("in"), res = 300)

#for viewing only do not run when saving
windows(height=6, width=9.75)

p <- ggplot(mdata_all, aes(y=pctcov, x=site)) 

p + geom_bar(position="fill", stat="identity", alpha = 0.8, 
             aes(fill=factor(lndcov)), colour = "black") +
  scale_fill_brewer(palette="BrBG", direction=-1)+
  theme_bw() + theme_minimal() +
  scale_y_continuous(limits = c(0,1), expand = c(0, 0)) +
  scale_x_continuous(breaks = seq(1,43,2), expand = c(0, 0)) +
  #axis.ticks.length = unit(half_line/2, "pt") 
  theme(text = element_text(size = 10)) + 
  ylab ("Percent Total Cover") +
  xlab ("Reaches") +
  theme(legend.position="top",legend.direction = "horizontal") + labs(fill = "Land Use") +
  guides(fill=guide_legend(nrow = 2)) +
  #theme(legend.position="top",legend.direction = "horizontal")+
  #guides(color=guide_legend(nrow=2, byrow=TRUE)) +
  theme(legend.title= element_text(size = rel(2))) +
  theme(legend.text = element_text(size = rel(1.25))) +
  theme(axis.title.y = element_text(size = rel(1.85))) +
  theme(axis.title.x = element_text(size = rel(1.85))) +
  theme(axis.text.x = element_text (size = rel(1.75))) + 
  theme(axis.text.y = element_text (size = rel(1.75))) + 
  theme(plot.title = element_text(size= rel(1.25)))


dev.off()

########################################################################################
#########################FCI results across all years  Figure 3 #################################################################
## Load data
hab <- read.csv("Current Data/1Total River_Attributes/Metrics/Reaches/hab_met21.csv")
hab <-hab[,-1]
hab_sites <-as.data.frame(hab)
print(head(hab, 10))

fci_44 <- NULL
fci<- NULL
fci_44 <- cbind(hab[,1:2])

bc <- (((hab$vegb+hab$simpb)/2+hab$fragb)/2)
fci_44$fci = ((hab$vegf+hab$simpf)/2+hab$fragf+bc)/3

con<-reshape2::dcast(fci_44, year~site)

#for saving only do not run the 'windows(height=6, width=9.75)' command when saving
jpeg('D:/Dropbox/publication/11th - portfolio/Applications Submission/Final Figures/figure 3_300.jpg', height=6, width=9.75, units=c("in"), res = 300)

#for viewing only do not run when saving
windows(height=6, width=9.75)

#set margins and get the labels from touching the tick marks
par(mar=c(6, 6, 4, 2) + 0.1 )
par(mgp = c(3,1,0))
boxplot(con[,-1],  las=1,ylab ="Assessment Score", xlab ="Reach",  main = "Floodplain Habitat Capacity",
        cex.lab=1.5, cex.axis=1, cex.main=2.5, cex.sub=1.5)
abline(h=0, lty=3, lwd= 3)
dev.off()


######################Figure 4 #########################

hab_sites_lu <- read.csv("Current Data/Final_hab_port_data/hab_sites21.csv")
hab <-hab_sites_lu[,-1]
hab_sites <-as.data.frame(hab)
print(head(hab_sites, 10))
hab_assets <- hab_sites

#color_zone
hab_assets_Ag_urb_x<- hab_assets[c(1:5),]
hab_assets_natural_x <- hab_assets[c(6,7,8,9,10,11,12,13,14,15,16,
                                     17,18,19,20,21,22,23,24,25,26,27,28,
                                     30),]
hab_assets_log_1 <- hab_assets[c(31:40),]
hab_assets_log_2 <- hab_assets[c(41:42),]
hab_assets_log_3 <- hab_assets[c(43:44),]

can_x3 <- cbind("Light Logging",hab_assets_log_3)
can_x2 <- cbind("Intensive Logging",hab_assets_log_2)
can_x1 <- cbind("Medium Logging",hab_assets_log_1)
glac_x <- cbind("Rural Lands",hab_assets_natural_x)
val_x <- cbind("Flathead Valley",hab_assets_Ag_urb_x )
nam <- c("zone", "Site", "er_p", "sd_p")
colnames(can_x3) <- nam
colnames(can_x2) <- nam
colnames(can_x1) <- nam
colnames(glac_x) <- nam
colnames(val_x) <- nam
hab_assets_x <- NULL
hab_assets_x <- rbind(val_x, glac_x, can_x1, can_x2, can_x3)

hab_assets_x <- as.data.frame(hab_assets_x)
hab_assets_x$er_p  <- as.numeric(as.character(hab_assets_x$er_p))
hab_assets_x$sd_p <- as.numeric(as.character(hab_assets_x$sd_p))
point_color <- c("#E69F00",  "#009e0b","#0b8dde", "#9e2800", "#363302")
hab_assets_x$zone <- factor(hab_assets_x$zone, 
                            levels = c("Flathead Valley", "Rural Lands", 
                                       "Medium Logging", "Intensive Logging", "Light Logging"))

###Final Figure
#for saving only do not run the 'windows(height=6, width=9.75)' command when saving
jpeg('D:/Dropbox/publication/11th - portfolio/Applications Submission/Final Figures/figure 4_300.jpg', height=6, width=9.75, units=c("in"), res = 300)

#for viewing only do not run when saving
windows(height=6, width=9.75)


ggplot(hab_assets_x, aes(x = sd_p, y = er_p, color = zone, label=as.character(Site))) +
  geom_point(size = 3.5) +
  scale_colour_manual(name  ="Reach", values = point_color)+
  theme_bw() + 
  xlab("System Volatility") + ylab("MMI Habitat Capacity Score") +
  geom_text_repel(size = rel(4), show.legend  = F) +
  theme(axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0))) +
  theme(legend.position="top",legend.direction = "horizontal")+
  guides(color=guide_legend(nrow=2, byrow=TRUE)) +
  theme(legend.title= element_text(size = rel(2))) +
  theme (legend.key.height = unit(-3, "cm"),
         legend.key.width = unit(-3, "cm"),
         legend.key.size = unit(0.1, "lines"))+
  theme(legend.text = element_text(size = rel(1.25))) +
  theme(axis.title.y = element_text(size = rel(1.85))) +
  theme(axis.title.x = element_text(size = rel(1.85))) +
  theme(axis.text.x = element_text (size = rel(1.75))) + 
  theme(axis.text.y = element_text (size = rel(1.75))) + 
  theme(plot.title = element_text(size= rel(1.25))) +
  scale_y_continuous(label = scales::percent, limits = c(min(hab_assets$er_p), max(hab_assets$er_p))) +
  scale_x_continuous(label = scales::percent_format(accuracy = 1)) +
  coord_cartesian(xlim = c(0.0,0.15))

dev.off()


################Figure 5#################################
####Land use over zones ###
logn <- NULL
data <- read.csv("Current Data/multi_sites/output/zone/2007_44_mrg_pct.csv")
logn <- cbind(logn,data$site)
for(yr in 1984:2020){
  data <- read.csv(sprintf("Current Data/multi_sites/output/zone/%d_44_mrg_pct.csv", yr), header = TRUE)
  data <- data[order(data[,1]),]
  data <- data[,-1]
  data <- data[order(names(data))]
  logn <- cbind(logn,data$pct.15)
}
nam <- c("site", 1984:2020)
colnames(logn) <-nam

logn <- as.data.table(logn)

lognm <- melt(logn, id=c("site"))
nam <- c("site", "year", "cover")
colnames(lognm) <-nam

# convert factor to numeric for convenience
lognm$site <- as.numeric(lognm$site)
nsites <- max(lognm$site)

# get the range for the x and y axis
lognm$year <- as.numeric(as.character(lognm$year))
xrange <- range(lognm$year)
#to get percent
lognm$cover <- lognm$cover*100
yrange <- range(lognm$cover)

###Final Figure
#for saving only do not run the 'windows(height=6, width=9.75)' command when saving
jpeg('D:/Dropbox/publication/11th - portfolio/Applications Submission/Final Figures/figure 5_300.jpg', height=6, width=9.75, units=c("in"), res = 300)

#for viewing only do not run when saving
windows(height=5, width=9.75)

plot(xrange, yrange, type="n", xlab="Years",
     ylab="Percent Logging Cover", cex.axis=1, cex.lab=1.5)
colors <- c("#E69F00", "#009e0b","#0b8dde", "#9e2800", "#363302")
linetype <- c(1:nsites)
plotchar <- seq(18,18+nsites,1)

for (i in 1:nsites) {
  site <- subset(lognm, site==i)
  lines(site$year, site$cover, type="b", lwd=3,
        lty=linetype[i], col=colors[i], pch=plotchar[i])
}
# add a title and subtitle
title("Logging Cover", cex.main=.5)

# add a legend
legend(xrange[1], yrange[2],bty="n", 1:nsites, cex=1.0, lwd=3, col=colors,
       pch=plotchar, lty=linetype, seg.len = 5, title="Zone")

dev.off()

#####################Figure 6#########################################
## Figure was made in excel





